{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### Imports"
      ],
      "metadata": {
        "id": "lQkOcaSmv4v0"
      },
      "id": "lQkOcaSmv4v0"
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "!pip install simcse\n",
        "!pip install gensim==4.1.2\n",
        "!pip install cython\n",
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import datasets\n",
        "from datasets import load_dataset, list_datasets\n",
        "import pandas as pd \n",
        "import re \n",
        "import numpy as np \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "from simcse import SimCSE\n",
        "random.seed(10)\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "from IPython.utils import io\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.models import FastText\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "1lcComPHv4Ia"
      },
      "id": "1lcComPHv4Ia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "fWXGTlQQwuCS"
      },
      "id": "fWXGTlQQwuCS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My\\ Drive/484-finalProject"
      ],
      "metadata": {
        "id": "X7Wa0JLNwv3I"
      },
      "id": "X7Wa0JLNwv3I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ba86871"
      },
      "source": [
        "##### Load Wikitext dataset (please run!)"
      ],
      "id": "0ba86871"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LbF0QkbhDYL"
      },
      "source": [
        "Headings without any text below it (i.g. only table) are excluded."
      ],
      "id": "8LbF0QkbhDYL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bb659e0"
      },
      "outputs": [],
      "source": [
        "class Node(object):\n",
        "    '''\n",
        "    each node contains \n",
        "    - parent \n",
        "    - children \n",
        "    - text\n",
        "    '''\n",
        "    def __init__(self,txt: str, level:int):\n",
        "        self.text = txt \n",
        "        self.level = level\n",
        "        self.parent = None \n",
        "        self.children = []\n",
        "    def insertChild(self,child):\n",
        "        self.children.append(child)\n",
        "    def linkParent(self, parent):\n",
        "        if(self.parent != None):\n",
        "            print(\"ERROR: node \", self.text, \"already has a parent\")\n",
        "        else:\n",
        "            self.parent = parent \n",
        "            \n",
        "        \n",
        "class Tree(object):\n",
        "    def __init__(self,document):\n",
        "        self.root = Node(document['title'],level=0)\n",
        "        self.depth = np.amax([v['type'] for v in document['document']], initial=0)\n",
        "        curNode = self.root \n",
        "        # para of format {\"text\", \"type\"}\n",
        "        for para in document['document']:\n",
        "            newNode = Node(para['text'],para['type'])\n",
        "            \n",
        "            # growing in depth\n",
        "            if(newNode.level == -1 or newNode.level > curNode.level):\n",
        "                curNode.insertChild(newNode)\n",
        "                newNode.linkParent(curNode)\n",
        "                if(newNode.level > 0):\n",
        "                    curNode = newNode \n",
        "                \n",
        "            # new heading belong to the same or lower level of subheading \n",
        "            else: \n",
        "                # trace back to the heading level that new heading is immediately under \n",
        "                while(curNode.level>=newNode.level):\n",
        "                    curNode = curNode.parent\n",
        "                curNode.insertChild(newNode)\n",
        "                newNode.linkParent(curNode)\n",
        "                curNode = newNode \n",
        "        return \n",
        "    \n",
        "    def printTree(self):\n",
        "        print(\"======== PRINTING TREE =========\")\n",
        "        print(\"TITLE: \", self.root.text)\n",
        "        print(\"MAX DEPTH: \", self.depth)\n",
        "        print(\"===============================\")\n",
        "        def printNode(curNode):\n",
        "            print(curNode.text)\n",
        "            if(curNode.level == -1):\n",
        "                return \n",
        "            \n",
        "            for child in curNode.children:\n",
        "                printNode(child)\n",
        "            return \n",
        "        printNode(self.root)\n",
        "  "
      ],
      "id": "3bb659e0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f09a8de0"
      },
      "outputs": [],
      "source": [
        "## helper functions \n",
        "\n",
        "# get type of text \n",
        "def checkHeading(txt):\n",
        "    if(txt == ''):\n",
        "        return -2\n",
        "    if(re.search(r'^\\s=.+\\s=\\s\\n',txt)):\n",
        "        return int(len(re.findall(r'\\s=',txt))/2 - 1)\n",
        "    return -1 \n",
        "\n",
        "# load documents to feed to tree \n",
        "def createDocuments(data):\n",
        "    documents_with = []\n",
        "    documents_without = []\n",
        "    document_with = []\n",
        "    document_without = []\n",
        "    curTitle = ''\n",
        "    for i in data:\n",
        "        c = checkHeading(i)\n",
        "        if(c==-2):\n",
        "            continue\n",
        "        if(c>-1):\n",
        "            # strip heading \n",
        "            i = re.findall(r'=\\s([^=]+)\\s=', i)[0]\n",
        "        if(c==0):\n",
        "            \n",
        "            # clear out empty headings \n",
        "            while(len(document_with)>1 and document_with[-1]['type']!=-1):\n",
        "                document_with.pop(-1)\n",
        "            documents_with.append({'title': curTitle, 'document':document_with})\n",
        "            documents_without.append(document_without)\n",
        "            curTitle = i\n",
        "            document_with = []\n",
        "            document_without = []\n",
        "            \n",
        "        else:\n",
        "            # clear out empty headings GOOFY HELP HOW TO CLEAN THIS UP \n",
        "            if(len(document_with)>1 and document_with[-1]['type']!=-1 and c <= document_with[-1]['type'] and c!=-1):\n",
        "                document_with.pop(-1)\n",
        "            document_with.append({'text':i,'type':c})\n",
        "            if(c==-1):\n",
        "                document_without.append(i)\n",
        "            \n",
        "    documents_with.pop(0)\n",
        "    documents_without.pop(0)\n",
        "    return documents_with, documents_without"
      ],
      "id": "f09a8de0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7ac6222"
      },
      "source": [
        "loadData() creates a list of data points containing the title of article, raw text (paragraphs), and the tree representation of heading structures."
      ],
      "id": "e7ac6222"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6f4ecfe"
      },
      "outputs": [],
      "source": [
        "## load wiki dataset \n",
        "def loadData(split='test', min_size=-1):\n",
        "    \"\"\"\n",
        "    prepare dataset for training, which is a list of dictionaries containing:  \n",
        "    - document title (string)\n",
        "    - paragraphs (list of string)\n",
        "    - tree representation of headings\n",
        "    \"\"\"\n",
        "    \n",
        "    data_raw = load_dataset(\"wikitext\",'wikitext-103-v1',split=split)\n",
        "    data_raw = data_raw['text']\n",
        "    documents_with, documents_without = createDocuments(data_raw)\n",
        "    \n",
        "    data = []\n",
        "    i = 0\n",
        "    for document in documents_with:\n",
        "        tree = Tree(document)\n",
        "        if len(documents_without[i]) < min_size:\n",
        "          continue\n",
        "#         tree.printTree()\n",
        "        data.append({\n",
        "            \"title\":document['title'],\n",
        "            \"paragraphs\":documents_without[i],\n",
        "            \"tree\": tree\n",
        "        })\n",
        "        i+=1\n",
        "    return data    "
      ],
      "id": "e6f4ecfe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDWF2apsjZT1"
      },
      "source": [
        "##### Preparing LCA loss evaluation function + tools for trees (please run!)"
      ],
      "id": "PDWF2apsjZT1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBXXXBS4jjcT"
      },
      "outputs": [],
      "source": [
        "# tree-related helper functions\n",
        "\n",
        "# iterate over a tree rooted at node in preorder traversal\n",
        "def preorder(node):\n",
        "    if len(node.children) == 0:\n",
        "        yield node\n",
        "    for ch in node.children:\n",
        "        yield from preorder(ch)\n",
        "\n",
        "# only prints leaves, i.e. text representations of paragraph\n",
        "# note: depends on accurate text, level population\n",
        "# text should be indices\n",
        "def print_tree(curNode):\n",
        "    if curNode.level == -1:\n",
        "        print(curNode.text, end='')\n",
        "        return\n",
        "    print('[', end='')\n",
        "    for idx, child in enumerate(curNode.children):\n",
        "        print_tree(child)\n",
        "        if idx < len(curNode.children) - 1:\n",
        "            print(', ', end='')\n",
        "    print(']', end='')\n",
        "    if curNode.level == 0:\n",
        "        print() # final print after entire tree is printed\n",
        "\n",
        "# text should be snippets\n",
        "def print_snippet_tree(curNode, indent='  '):\n",
        "    if curNode.level == -1:\n",
        "        print(indent + curNode.text, end='')\n",
        "        return\n",
        "    print(indent+'[heading]')\n",
        "    for idx, child in enumerate(curNode.children):\n",
        "        print_snippet_tree(child, indent+'  ')\n",
        "        if idx < len(curNode.children) - 1:\n",
        "            print()\n",
        "    if curNode.level == 0:\n",
        "        print() # final print after entire tree is printed\n",
        "\n",
        "def clone_tree(root):\n",
        "    root_copy = Node(root.text, root.level)\n",
        "    for ch in root.children:\n",
        "        root_copy.insertChild(clone_tree(ch))\n",
        "        root_copy.children[-1].linkParent(root_copy)\n",
        "    return root_copy\n",
        "\n",
        "# return indexified tree with text as paragraphs to text as indices of paragraphs for more concise printing\n",
        "def indexified_tree(root):\n",
        "    root_copy = clone_tree(root)\n",
        "    for idx, node in enumerate(preorder(root_copy)):\n",
        "        node.text = idx\n",
        "    return root_copy\n",
        "\n",
        "# return indexified tree with text as paragraphs to text as indices of paragraphs for more concise printing\n",
        "def textified_tree(root, paras):\n",
        "    root_copy = clone_tree(root)\n",
        "    for idx, node in enumerate(preorder(root_copy)):\n",
        "        node.text = paras[idx][:40] + '...'\n",
        "    return root_copy\n",
        "\n",
        "# print_tree(roots[0])\n",
        "# print_tree(train_y[0].root)"
      ],
      "id": "IBXXXBS4jjcT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9hZqeHXjef7"
      },
      "outputs": [],
      "source": [
        "# lca-related helper functions and lca loss\n",
        "# note: assumed indexified trees\n",
        "def trace_helper(node, i, trace):\n",
        "    if node.text == i:\n",
        "        return True\n",
        "    for idx, ch in enumerate(node.children):\n",
        "        if trace_helper(ch, i, trace):\n",
        "            trace.append(idx)\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def get_trace(root, i):\n",
        "    trace = []\n",
        "    trace_helper(root, i, trace)\n",
        "    trace.reverse()\n",
        "    return trace\n",
        "\n",
        "def compute_lca_dist(root, i, j):\n",
        "    trace_i = get_trace(root, i)\n",
        "    trace_j = get_trace(root, j)\n",
        "    # print(trace_i)\n",
        "    # print(trace_j)\n",
        "    for idx in range(min(len(trace_i), len(trace_j))):\n",
        "        if trace_i[idx] != trace_j[idx]:\n",
        "            return len(trace_i) + len(trace_j) - 2 * idx\n",
        "    return len(trace_i) + len(trace_j)\n",
        "\n",
        "def lca_loss(root1, root2, num_paras):\n",
        "    loss = 0\n",
        "    for i in range(2, num_paras+1): # 1-indexed from indexify\n",
        "        j = i-1\n",
        "        dist1 = compute_lca_dist(root1, i, j)\n",
        "        dist2 = compute_lca_dist(root2, i, j)\n",
        "        # print(i, j, dist1, dist2)\n",
        "        loss += (dist1 - dist2) * (dist1 - dist2)\n",
        "    if num_paras == 1:\n",
        "        return loss\n",
        "    return loss / (num_paras - 1)\n",
        "\n",
        "def batch_lca_loss(roots1, roots2, num_paras):\n",
        "    tt = 0\n",
        "    for root1, root2, num in zip(roots1, roots2, num_paras):\n",
        "        tt += lca_loss(root1, root2, num)\n",
        "    return tt / len(roots1)"
      ],
      "id": "z9hZqeHXjef7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpclBBYffxaL"
      },
      "source": [
        "##### Model 2: Greedy decoding + LCA loss"
      ],
      "id": "HpclBBYffxaL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgFl1lNDWKmv"
      },
      "outputs": [],
      "source": [
        "MAX_DEPTH = 8\n",
        "class GreedyDecoder:\n",
        "    def __init__(self, thresholds, similarity, encode):\n",
        "        self.thresholds = thresholds\n",
        "        self.similarity = similarity\n",
        "        self.encode = encode\n",
        "    \n",
        "    # add level and parent info to a tree rooted at node\n",
        "    def update_levels_parents(self, node, depth):\n",
        "        # print(node.text)\n",
        "        if len(node.children) == 0: # leaf paragraph node\n",
        "            node.level = -1\n",
        "            return\n",
        "        node.level = depth\n",
        "        for ch in node.children:\n",
        "            ch.linkParent(node)\n",
        "            self.update_levels_parents(ch, depth+1)\n",
        "\n",
        "    # decodes and returns tree rooted at node\n",
        "    def encode_decode(self, paragraphs):\n",
        "        embs = []\n",
        "        for para in paragraphs:\n",
        "            embs.append(self.encode(para))\n",
        "        return self.decode(embs)\n",
        "    \n",
        "    # decodes and returns tree rooted at node, with text fields populated, e.g. for printing the tree\n",
        "    def encode_decode_with_text(self, X, indexify=True):\n",
        "        root = self.encode_decode(X)\n",
        "        for idx, leaf in enumerate(preorder(root)):\n",
        "            if indexify:\n",
        "                leaf.text = idx\n",
        "            else:\n",
        "                leaf.text = X[idx]\n",
        "        return root\n",
        "    \n",
        "    # here X and y are lists\n",
        "    def batch_encode_decode_with_text(self, X):\n",
        "        roots = []\n",
        "        for X_i in X:\n",
        "            roots.append(self.encode_decode_with_text(X_i))\n",
        "        return roots\n",
        "\n",
        "    # bottom up decoding: for each depth, join paragraphs whose pairwise similarity reaches the threshold\n",
        "    # and represent them collectively by the mean of their embeddings\n",
        "    def decode(self, embs):\n",
        "        if len(embs) == 0:\n",
        "            return Node('', 0) # should never happen\n",
        "        roots = []\n",
        "        for i in range(len(embs)):\n",
        "            roots.append(Node(i, -1))\n",
        "        dim = embs[0].shape[0]\n",
        "        for depth in range(MAX_DEPTH-1): # in last layer, everything must be joined together\n",
        "            next_idxs = [[0]]\n",
        "            for i in range(1, len(embs)):\n",
        "                if self.similarity(embs[i-1], embs[i]) >= self.thresholds[depth]:\n",
        "                    next_idxs[-1].append(i)\n",
        "                else:\n",
        "                    next_idxs.append([i])\n",
        "\n",
        "            # print(next_idxs)\n",
        "            # for root in roots:\n",
        "            #     print_tree(root)\n",
        "\n",
        "            # update roots and embs\n",
        "            next_roots = []\n",
        "            next_embs = []\n",
        "            for comp in next_idxs:\n",
        "                # don't add trivial (1 -> 1) edges\n",
        "                if len(comp) == 1:\n",
        "                    next_roots.append(roots[comp[0]])\n",
        "                    next_embs.append(embs[comp[0]])\n",
        "                    continue\n",
        "\n",
        "                next_roots.append(Node('', -2)) # meaningless params since we only need tree structure\n",
        "                next_embs.append(torch.zeros(dim))\n",
        "                for idx in comp:\n",
        "                    next_roots[-1].insertChild(roots[idx])\n",
        "                    next_embs[-1] += embs[idx]\n",
        "                next_embs[-1] /= len(comp)\n",
        "            roots = next_roots\n",
        "            embs = next_embs\n",
        "        \n",
        "        # join everything together in the last layer\n",
        "        root = Node('', 0)\n",
        "        for node in roots:\n",
        "            root.insertChild(node)\n",
        "\n",
        "        # update parents and levels, then return\n",
        "        self.update_levels_parents(root, 0)\n",
        "        return root"
      ],
      "id": "MgFl1lNDWKmv"
    },
    {
      "cell_type": "code",
      "source": [
        "doc2vec_model = Doc2Vec.load(\"models/{}_d2v.model\".format(256))\n",
        "simcse_model = SimCSE(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
        "\n",
        "def sim(v1, v2):\n",
        "      # return torch.dot(v1, v2) / torch.norm(torch.sub(v1, v2))\n",
        "      return torch.dot(v1, v2) / (torch.norm(v1) * torch.norm(v2))\n",
        "\n",
        "def doc2vec_enc(v):\n",
        "    return torch.tensor(doc2vec_model.infer_vector(word_tokenize(v)))\n",
        "\n",
        "def simcse_enc(v):\n",
        "    para = re.sub('\\n', '', v)\n",
        "    sents = re.split('[.]|[!]|[?]', para.strip())\n",
        "    with io.capture_output() as captured:\n",
        "        vecs = simcse_model.encode(sents, device=device, batch_size=len(sents))\n",
        "    return torch.mean(vecs, dim=0)\n",
        "\n",
        "def get_doc2vec_greedy():\n",
        "  # thresholds = [1.769, 1.261, 0.007, 2.289, 1.793, 0.590, 3.620, 3.969] # 128 thresholds\n",
        "  thresholds = [1.769, 1.261, 0.007, 2.289, 1.793, 0.590, 3.620, 3.969] # 256 thresholds\n",
        "  greedy = GreedyDecoder(thresholds, similarity=sim, encode=doc2vec_enc)\n",
        "  return greedy\n",
        "\n",
        "def get_simcse_greedy(use_proj=False, mlp=None):\n",
        "  thresholds = [1.668, 0.429, 0.810, 2.581, 1.015, 1.205, 1.755, 0.440] # simcse thresholds\n",
        "  greedy = GreedyDecoder(thresholds, similarity=sim, encode=mlp.emb.embed_one_para if use_proj else simcse_enc)\n",
        "  return greedy\n",
        "\n",
        "def get_fasttext_greedy(use_proj=False, mlp=None):\n",
        "  thresholds = [1.41, 0.55, 1.72, 0.47, 2.8, 2.35, 1.3, 0.21]\n",
        "  greedy = GreedyDecoder(thresholds, similarity=sim, encode=mlp.emb.embed_one_para if use_proj else None)\n",
        "  return greedy"
      ],
      "metadata": {
        "id": "bez2ulDdzSA9"
      },
      "id": "bez2ulDdzSA9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njWi7UimNnjJ"
      },
      "outputs": [],
      "source": [
        "def evaluate_thresholds(X, y, thresholds, similarity=sim, encode=doc2vec_enc):\n",
        "    greedy = GreedyDecoder(thresholds, similarity=similarity, encode=encode)\n",
        "    y_hat = greedy.batch_encode_decode_with_text(X)\n",
        "    y = [indexified_tree(y_i.root) for y_i in y]\n",
        "    lens = [len(x) for x in X]\n",
        "    return batch_lca_loss(y, y_hat, lens)\n",
        "    # print('Actual:')\n",
        "    # print_tree(y_hat[0])\n",
        "    # print('Predicted:')\n",
        "    # print_tree(y[0])\n",
        "\n",
        "def random_search(X, y, n_tries=50, min_num=[0]*8, max_num=[3]*8, similarity=sim, encode=doc2vec_enc):\n",
        "    results = []\n",
        "    for i in range(n_tries):\n",
        "        print('try #' + str(i))\n",
        "        thresholds = []\n",
        "        for j in range(8):\n",
        "            thresholds.append(random.uniform(min_num[j],max_num[j]))\n",
        "        # print('thresholds:', thresholds)\n",
        "        loss = evaluate_thresholds(X, y, thresholds, similarity=similarity, encode=encode)\n",
        "        results.append({'loss':loss, 'thresholds':thresholds})\n",
        "    \n",
        "    # print sorted version by each index\n",
        "    print('printing sorted by component...')\n",
        "    for i in range(8):\n",
        "        print('component', i)\n",
        "        results_sorted = sorted(results, key=lambda x: x['thresholds'][i])\n",
        "        for result in results_sorted:\n",
        "            thresh =  [\"{0:0.5f}\".format(i) for i in result['thresholds']]\n",
        "            print(result['loss'], '\\t', thresh)\n",
        "        print()"
      ],
      "id": "njWi7UimNnjJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc5HGcLzgoFv"
      },
      "source": [
        "##### Model 3: Recursive split MLP"
      ],
      "id": "yc5HGcLzgoFv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvpuvYJnhci0"
      },
      "outputs": [],
      "source": [
        "def recur_search(node, to_be_marked, curr_data):\n",
        "  if node.level == -1:\n",
        "    curr_data.append(([n.level for n in to_be_marked], node.parent.level + 1))  # add data of which nodes you are first of, and also what is your depth\n",
        "    to_be_marked = []\n",
        "    return to_be_marked\n",
        "  to_be_marked.append(node)\n",
        "  for child in node.children:\n",
        "    to_be_marked = recur_search(child, to_be_marked, curr_data)\n",
        "  return to_be_marked\n",
        "\n",
        "def convert_dataset(data, window_size):\n",
        "  paras, trees = [d['paragraphs'] for d in data], [d['tree'] for d in data]\n",
        "  dataX, dataD, datay = [], [], []\n",
        "  for i in range(len(paras)):  # for each article\n",
        "    article = paras[i]\n",
        "    curr_data = []\n",
        "    recur_search(trees[i].root, [], curr_data)\n",
        "    for p in range(len(article)):  # for each paragraph\n",
        "      context = []\n",
        "      for j in range(p - window_size, p + window_size + 1):  # for para in context\n",
        "        if j < 0 or j >= len(article):\n",
        "          context.append(None)\n",
        "        else:\n",
        "          context.append(article[j])\n",
        "      breaks, depth = curr_data[p]\n",
        "      print(breaks, '  d=', depth, '    ', article[p][:20])\n",
        "      for d in range(0 if p == 0 else 1, depth):\n",
        "        dataX.append(context)\n",
        "        dataD.append([d])\n",
        "        datay.append([1 if d in breaks else 0])\n",
        "  dataD = torch.tensor(np.array(dataD))\n",
        "  datay = torch.tensor(np.array(datay))\n",
        "  return dataX, dataD, datay"
      ],
      "id": "cvpuvYJnhci0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cUSNy2ATU6C"
      },
      "outputs": [],
      "source": [
        "# MODULES FOR EMBEDDING 3 DIFFERENT WAYS: DOC2VEC, PROJECTED SIMCSE, PROJECTED FASTTEXT\n",
        "# each one takes a batch of lists of paragraphs, outputs a batch of concatenated paragraph embeddings\n",
        "# forward pass input: batch (len B) of list of paragraphs (len 2 * window_size + 1), each para variable length\n",
        "# forward pass output: tensor of size B x ((2 * window_size + 1) * emb_dim)\n",
        "# each one can also embed one paragraph at a time\n",
        "class Doc2VecEmbedding(nn.Module):\n",
        "  def __init__(self, window_size, emb_dim): \n",
        "    super().__init__()\n",
        "    self.emb_dim = emb_dim\n",
        "    self.doc2vec = Doc2Vec.load(\"models/{}_d2v.model\".format(emb_dim))\n",
        "  \n",
        "  def embed_one_para(self, p):\n",
        "    return torch.tensor(self.doc2vec.infer_vector(word_tokenize(p.lower())) if p is not None else np.zeros(shape=(self.emb_dim))).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    with torch.no_grad():\n",
        "      batch = []\n",
        "      for b in x:\n",
        "        paras = []\n",
        "        for p in b:\n",
        "          paras.append(self.doc2vec.infer_vector(word_tokenize(p.lower())) if p is not None else np.zeros(shape=(self.emb_dim)))\n",
        "        batch.append(np.concatenate(paras, axis=0))\n",
        "      return torch.tensor(np.stack(batch, axis=0)).to(device)\n",
        "\n",
        "class SimCSEEmbedding(nn.Module):\n",
        "  def __init__(self, window_size, emb_dim, dropout): \n",
        "    super().__init__()\n",
        "    self.window_size = window_size\n",
        "    self.emb_dim = emb_dim\n",
        "    self.simcse = SimCSE(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
        "    self.SIMCSE_DIM = 768 # dim of simcse sentence embeddings\n",
        "    self.lstm = nn.LSTM(input_size=self.SIMCSE_DIM,\n",
        "                        hidden_size=int(emb_dim / 4),\n",
        "                        num_layers=1,\n",
        "                        bidirectional=True,\n",
        "                        batch_first=True, \n",
        "                        dropout=0.0).to(device)\n",
        "\n",
        "  def embed_one_para(self, p):\n",
        "    p = re.sub('\\n', '', p)\n",
        "    sents = re.split('[.]|[!]|[?]', p.strip())\n",
        "    with io.capture_output() as captured:\n",
        "        sents_emb = self.simcse.encode(sents, device=device, batch_size=len(sents), max_length=64)  # a tensor of len(sents) x SIMCSE_DIM\n",
        "    sents_emb = torch.nn.utils.rnn.pad_sequence([sents_emb], batch_first=True).to(device)\n",
        "    packed_in = torch.nn.utils.rnn.pack_padded_sequence(sents_emb, torch.tensor([a.shape[0] for a in sents_emb]), batch_first=True, enforce_sorted=False)\n",
        "    _, (hidden, cell) = self.lstm(packed_in.to(device))\n",
        "    para_emb = torch.cat((hidden[0], cell[0], hidden[1], cell[1]), dim=1).squeeze().cpu()\n",
        "    return para_emb\n",
        "\n",
        "  def forward(self, x):\n",
        "    B = len(x)  # batch size\n",
        "    batch = []\n",
        "    with torch.no_grad():\n",
        "      for b in x:\n",
        "        for p in b:\n",
        "          if p is not None:\n",
        "            p = re.sub('\\n', '', p)\n",
        "            sents = re.split('[.]|[!]|[?]', p.strip())\n",
        "            with io.capture_output() as captured:\n",
        "                sents_emb = self.simcse.encode(sents, device=device, batch_size=len(sents), max_length=64)  # a tensor of len(sents) x SIMCSE_DIM\n",
        "            batch.append(sents_emb)\n",
        "          else:\n",
        "            batch.append(torch.zeros((1, self.SIMCSE_DIM), device=device))\n",
        "      batch_emb = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True).to(device)\n",
        "      packed_in = torch.nn.utils.rnn.pack_padded_sequence(batch_emb, torch.tensor([a.shape[0] for a in batch_emb]), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "    _, (hidden, cell) = self.lstm(packed_in.to(device))\n",
        "    para_embs = torch.cat((hidden[0], cell[0], hidden[1], cell[1]), dim=1)        \n",
        "      \n",
        "    return para_embs.reshape(B, (2 * self.window_size + 1) * self.emb_dim)\n",
        "\n",
        "\n",
        "class FastTextEmbedding(nn.Module):\n",
        "  def __init__(self, window_size, emb_dim, dropout): \n",
        "    super().__init__()\n",
        "    self.window_size = window_size\n",
        "    self.emb_dim = emb_dim\n",
        "    self.fasttext = FastText.load_fasttext_format('models/fast-text-300.bin').wv\n",
        "    self.FASTTEXT_DIM = 300 # dim of fasttext word embeddings\n",
        "    self.lstm = nn.LSTM(input_size=self.FASTTEXT_DIM,\n",
        "                        hidden_size=int(emb_dim / 4),\n",
        "                        num_layers=1,\n",
        "                        bidirectional=True,\n",
        "                        batch_first=True, \n",
        "                        dropout=0.0).to(device)\n",
        "\n",
        "  def embed_one_para(self, p):\n",
        "    p = re.sub('\\n', '', p)\n",
        "    words = re.sub(\"[^\\s\\w]\", \"\", p.strip()).split(' ')\n",
        "    words = list(filter(None, words))\n",
        "    if len(words) == 0:\n",
        "        return torch.zeros((self.FASTTEXT_DIM))\n",
        "    words_emb = torch.stack([torch.tensor(self.fasttext[word]) for word in words]).to(device)  # a tensor of len(words) x FASTTEXT_DIM\n",
        "    words_emb = torch.nn.utils.rnn.pad_sequence([words_emb], batch_first=True).to(device)\n",
        "    packed_in = torch.nn.utils.rnn.pack_padded_sequence(words_emb, torch.tensor([a.shape[0] for a in words_emb]), batch_first=True, enforce_sorted=False)\n",
        "    _, (hidden, cell) = self.lstm(packed_in.to(device))\n",
        "    para_emb = torch.cat((hidden[0], cell[0], hidden[1], cell[1]), dim=1).squeeze().cpu()\n",
        "    return para_emb\n",
        "\n",
        "  def forward(self, x):\n",
        "    B = len(x)  # batch size\n",
        "    batch = []\n",
        "    with torch.no_grad():\n",
        "      for b in x:\n",
        "        for p in b:\n",
        "          if p is not None:\n",
        "            p = re.sub('\\n', '', p)\n",
        "            words = re.sub(\"[^\\s\\w]\", \"\", p.strip()).split(' ')\n",
        "            words = list(filter(None, words))\n",
        "            if len(words) == 0:\n",
        "                batch.append(torch.zeros((1, self.FASTTEXT_DIM)))\n",
        "                continue\n",
        "            words_emb = torch.stack([torch.tensor(self.fasttext[word]) for word in words]).to(device)  # a tensor of len(words) x FASTTEXT_DIM\n",
        "            batch.append(words_emb)\n",
        "          else:\n",
        "            batch.append(torch.zeros((1, self.FASTTEXT_DIM), device=device))\n",
        "      batch_emb = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True).to(device)\n",
        "      packed_in = torch.nn.utils.rnn.pack_padded_sequence(batch_emb, torch.tensor([a.shape[0] for a in batch_emb]), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "    _, (hidden, cell) = self.lstm(packed_in.to(device))\n",
        "    para_embs = torch.cat((hidden[0], cell[0], hidden[1], cell[1]), dim=1)        \n",
        "      \n",
        "    return para_embs.reshape(B, (2 * self.window_size + 1) * self.emb_dim)"
      ],
      "id": "5cUSNy2ATU6C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2ayqAuIhqjt"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, layer_dims, window_size, emb_dim, emb_method, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.emb_dim = emb_dim # dimension of each paragraph embedding\n",
        "        if emb_method == 'doc2vec':\n",
        "          self.emb = Doc2VecEmbedding(window_size, emb_dim)\n",
        "        elif emb_method == 'simcse':\n",
        "          self.emb = SimCSEEmbedding(window_size, emb_dim, dropout=dropout)\n",
        "        elif emb_method == 'fasttext':\n",
        "          self.emb = FastTextEmbedding(window_size, emb_dim, dropout=dropout)\n",
        "        else:\n",
        "          raise NotImplementedError()\n",
        "\n",
        "        in_feats = (2 * window_size + 1) * self.emb_dim\n",
        "        self.layers = []\n",
        "        for dim in layer_dims:\n",
        "          self.layers.append(nn.Linear(in_features=in_feats + 1, out_features=dim))\n",
        "          in_feats = dim\n",
        "        self.layers.append(nn.Linear(in_features=in_feats + 1, out_features=1))\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, d):\n",
        "      '''\n",
        "      x is a batch (list) of windows (list) of paragraphs, which are strings\n",
        "      d is the depths for the whole batch (tensor)\n",
        "      '''\n",
        "      B = len(x)\n",
        "      x = self.emb(x).float()  # x is a (B x (2W + 1) x E) tensor\n",
        "      x = x.reshape(B, (2 * self.window_size + 1) * self.emb_dim)\n",
        "      for layer in self.layers[:-1]:\n",
        "        x = F.relu(layer(torch.cat((x, d), dim=1)))\n",
        "      x = self.dropout(x)\n",
        "      x = torch.sigmoid(self.layers[-1](torch.cat((x, d), dim=1)))\n",
        "      return x\n",
        "\n",
        "  def recursive_outline(self, indices, node, threshold, growth, contexts, wordy):\n",
        "    window_size = int((len(contexts[0]) - 1) / 2)\n",
        "    if len(indices) == 0:\n",
        "        return\n",
        "    if len(indices) == 1:\n",
        "        new = Node(contexts[indices[0]][window_size], -1)\n",
        "        new.linkParent(node)\n",
        "        node.insertChild(new)\n",
        "        return\n",
        "    outs = []\n",
        "    for i in indices:\n",
        "        X = [contexts[i]]\n",
        "        D = torch.tensor([node.level + 1]).to(device).unsqueeze(dim=0)\n",
        "        out = self.forward(X, D).squeeze()\n",
        "        if wordy:\n",
        "          print(out.cpu().item(), D.cpu().item(), '       ', contexts[i][window_size][:40])\n",
        "        t = threshold if node.level < 1 else threshold * (growth ** (node.level + 1))\n",
        "        outs.append(out.cpu().item() > t)\n",
        "    prev = 0\n",
        "    flag = True\n",
        "    for o in range(1, len(outs)):\n",
        "        if outs[o]:\n",
        "            if o - prev > 1:\n",
        "              new = Node('', node.level + 1)\n",
        "              new.linkParent(node)\n",
        "              node.insertChild(new)\n",
        "              self.recursive_outline(indices[prev:o], new, threshold, growth, contexts, wordy)\n",
        "            elif o - prev == 1:\n",
        "              new = Node(contexts[indices[prev]][window_size], -1)\n",
        "              new.linkParent(node)\n",
        "              node.insertChild(new)\n",
        "              prev = o\n",
        "              continue\n",
        "            else:\n",
        "              continue\n",
        "            prev = o\n",
        "            flag = False\n",
        "    if flag:\n",
        "      for i in indices:\n",
        "        new = Node(contexts[i][window_size], -1)\n",
        "        new.linkParent(node)\n",
        "        node.insertChild(new)\n",
        "    else:\n",
        "       new = Node('', node.level + 1)\n",
        "       new.linkParent(node)\n",
        "       node.insertChild(new)\n",
        "       self.recursive_outline(indices[prev:], new, threshold, growth, contexts, wordy)\n",
        "    return\n",
        "\n",
        "  def outline(self, article, threshold=0.17, growth=1.6, wordy=False):\n",
        "      self.eval()\n",
        "      contexts = []\n",
        "      for p in range(len(article)):\n",
        "        context = []\n",
        "        for j in range(p - self.window_size, p + self.window_size + 1):\n",
        "            if j < 0 or j >= len(article):\n",
        "                context.append(None)\n",
        "            else:\n",
        "                context.append(article[j])\n",
        "        contexts.append(context)\n",
        "\n",
        "      indices = list(range(len(article)))  # indices to recur with\n",
        "      root = Node('root', 0)\n",
        "      self.recursive_outline(indices, root, threshold, growth, contexts, wordy)\n",
        "\n",
        "      def printNode(curNode):\n",
        "          print(curNode.level, '       ', curNode.text[:50])\n",
        "          if curNode.level == -1:\n",
        "              return\n",
        "\n",
        "          for child in curNode.children:\n",
        "              printNode(child)\n",
        "          return\n",
        "\n",
        "      if wordy:\n",
        "        printNode(root)\n",
        "      return root\n",
        "\n",
        "  def save(self, path: str):\n",
        "      \"\"\" Save the model to a file.\n",
        "      @param path (str): path to the model\n",
        "      \"\"\"\n",
        "\n",
        "      params = {\n",
        "          # 'args': dict(hid_dim=self.hid_dim, n_layers=self.n_layers, num_heads=self.num_heads,\n",
        "          #       num_enc_layers=self.num_enc_layers, num_dec_layers=self.num_dec_layers, ff_dim=self.ff_dim, dropout=self.dropout),\n",
        "          'state_dict': self.state_dict()\n",
        "      }\n",
        "\n",
        "      torch.save(params, path)\n"
      ],
      "id": "K2ayqAuIhqjt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hy4A11xhwzd"
      },
      "outputs": [],
      "source": [
        "# RUN THIS CELL FOR DOC2VEC MLP MODEL, with either SMALL or LARGE to indicate model size\n",
        "def get_doc2vec_mlp(use_large):\n",
        "  LARGE = use_large  # make this true to use larger model\n",
        "  MODEL_PATH = 'checkpoints/{}'.format('test_large_mlp_doc2vec.bin' if LARGE else 'test_mlp_doc2vec.bin')\n",
        "  # MODEL_PATH = 'checkpoints/{}'.format('mlp_big_windowdoc2vec.bin')\n",
        "\n",
        "\n",
        "  WINDOW_SIZE = 4 if LARGE else 3  # number of neighbors to consider in each direction\n",
        "  EMB_DIM = 256  # dim each paragraph becomes, via magic :)\n",
        "  EMB_METHOD = 'doc2vec'  # one of 'doc2vec', 'simcse', 'fasttext'\n",
        "  MLP_ARCHITECTURE = [5096, 1024, 256, 64] if LARGE else [1024, 256, 64]  # sizes of hidden layers in MLP\n",
        "\n",
        "  model = MLP(layer_dims=MLP_ARCHITECTURE, window_size=WINDOW_SIZE, emb_dim=EMB_DIM, emb_method=EMB_METHOD)\n",
        "  params = torch.load(MODEL_PATH, map_location=lambda storage, loc: storage)\n",
        "  model.load_state_dict(params['state_dict'])\n",
        "  model = model.to(device)\n",
        "  model.eval()\n",
        "  return model"
      ],
      "id": "3hy4A11xhwzd"
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CELL FOR FASTTEXT MLP MODEL, with either SMALL or LARGE to indicate model size\n",
        "def get_fasttext_mlp(use_large):\n",
        "  LARGE = use_large  # make this true to use larger model\n",
        "  MODEL_PATH = 'checkpoints/{}'.format('test_large_mlp_fasttext.bin' if LARGE else 'mlp_fasttext.bin')\n",
        "\n",
        "\n",
        "  WINDOW_SIZE = 4 if LARGE else 2  # number of neighbors to consider in each direction\n",
        "  EMB_DIM = 512 if LARGE else 256  # dim each paragraph becomes, via magic :)\n",
        "  EMB_METHOD = 'fasttext'  # one of 'doc2vec', 'simcse', 'fasttext'\n",
        "  MLP_ARCHITECTURE = [5096, 1024, 256, 64] if LARGE else [1024, 256, 64]  # sizes of hidden layers in MLP\n",
        "\n",
        "  model = MLP(layer_dims=MLP_ARCHITECTURE, window_size=WINDOW_SIZE, emb_dim=EMB_DIM, emb_method=EMB_METHOD)\n",
        "  params = torch.load(MODEL_PATH, map_location=lambda storage, loc: storage)\n",
        "  model.load_state_dict(params['state_dict'])\n",
        "  model = model.to(device)\n",
        "  model.eval()\n",
        "  return model"
      ],
      "metadata": {
        "id": "Y9TGJj8zuPae"
      },
      "id": "Y9TGJj8zuPae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CELL FOR SIMCSE MLP MODEL\n",
        "def get_simcse_mlp():\n",
        "  MODEL_PATH = 'checkpoints/{}'.format('test_mlp_simcse.bin')\n",
        "  # MODEL_PATH = 'checkpoints/{}'.format('evan_mlp_simcse.bin')\n",
        "  # MODEL_PATH = 'checkpoints/{}'.format('mlp_simcse.bin')\n",
        "\n",
        "\n",
        "  WINDOW_SIZE = 3  # number of neighbors to consider in each direction\n",
        "  EMB_DIM = 256  # dim each paragraph becomes, via magic :)\n",
        "  EMB_METHOD = 'simcse'  # one of 'doc2vec', 'simcse', 'fasttext'\n",
        "  MLP_ARCHITECTURE = [1024, 256, 64]  # sizes of hidden layers in MLP\n",
        "\n",
        "  model = MLP(layer_dims=MLP_ARCHITECTURE, window_size=WINDOW_SIZE, emb_dim=EMB_DIM, emb_method=EMB_METHOD)\n",
        "  params = torch.load(MODEL_PATH, map_location=lambda storage, loc: storage)\n",
        "  model.load_state_dict(params['state_dict'])\n",
        "  model = model.to(device)\n",
        "  model.eval()\n",
        "  return model"
      ],
      "metadata": {
        "id": "997HjOI_uSxH"
      },
      "id": "997HjOI_uSxH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Eval"
      ],
      "metadata": {
        "id": "-rQyHXdTvdZr"
      },
      "id": "-rQyHXdTvdZr"
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD DATASET\n",
        "# train = loadData('train')\n",
        "val = loadData('validation')\n",
        "test = loadData('test')\n",
        "test.extend(val)"
      ],
      "metadata": {
        "id": "9Tx_JNuY1O3S"
      },
      "id": "9Tx_JNuY1O3S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAKE MODELS\n",
        "# mlp = get_doc2vec_mlp(use_large=True)\n",
        "mlp = get_simcse_mlp()\n",
        "# mlp = get_fasttext_mlp(use_large=True)\n",
        "\n",
        "# greedy = get_doc2vec_greedy()\n",
        "greedy = get_simcse_greedy(use_proj=False, mlp=mlp)\n",
        "# greedy = get_fasttext_greedy(use_proj=True, mlp=mlp)"
      ],
      "metadata": {
        "id": "XXjemQMpywbm"
      },
      "id": "XXjemQMpywbm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN MLP OVER WHOLE SAMPLE SET\n",
        "from tqdm import tqdm\n",
        "\n",
        "sample = test\n",
        "roots = []\n",
        "for i in tqdm(range(len(sample))):\n",
        "  out = mlp.outline(sample[i]['paragraphs'], threshold=0.15, growth=2.0, wordy=False)\n",
        "  roots.append(indexified_tree(out))\n",
        "\n",
        "golds = [indexified_tree(a['tree'].root) for a in sample]\n",
        "lens = [len(a['paragraphs']) for a in sample]\n",
        "print(batch_lca_loss(golds, roots, lens))"
      ],
      "metadata": {
        "id": "IQN6KMA02UWB"
      },
      "id": "IQN6KMA02UWB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN GREEDY OVER WHOLE SAMPLE SET\n",
        "sample = test\n",
        "X, y = [d['paragraphs'] for d in sample], [d['tree'] for d in sample]\n",
        "y_hat = greedy.batch_encode_decode_with_text(X)\n",
        "y = [indexified_tree(y_i.root) for y_i in y]\n",
        "lens = [len(x) for x in X]\n",
        "# print(batch_lca_loss(y, y_hat, lens))\n",
        "print(lca_loss(y[0], y_hat[0], lens[0]))"
      ],
      "metadata": {
        "id": "gOZufi4Q2lfK"
      },
      "id": "gOZufi4Q2lfK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INFERENCE MODELS ON INDIVIDUAL DATA POINTS\n",
        "# 23672 from train is is Dan Dugan\n",
        "sample_i = 23672\n",
        "sample = train\n",
        "\n",
        "y_hat_mlp = mlp.outline(sample[sample_i]['paragraphs'], threshold=0.25, growth=2.0, wordy=False)\n",
        "y_hat_greedy = greedy.encode_decode_with_text(sample[sample_i]['paragraphs'])\n",
        "\n",
        "print('---------------MLP------------------')\n",
        "print_snippet_tree(textified_tree(y_hat_mlp, sample[sample_i]['paragraphs']))\n",
        "print()\n",
        "print()\n",
        "print('---------------GREEDY------------------')\n",
        "print_snippet_tree(textified_tree(y_hat_greedy, sample[sample_i]['paragraphs']))\n",
        "print()\n",
        "print()\n",
        "print('---------------GROUND TRUTH------------------')\n",
        "print_snippet_tree(textified_tree(sample[sample_i]['tree'].root, sample[sample_i]['paragraphs']))\n"
      ],
      "metadata": {
        "id": "BktJ6fck08h4"
      },
      "id": "BktJ6fck08h4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "\n",
        "def Nmaxelements(list1, N):\n",
        "    final_list = []\n",
        "    for i in range(N): \n",
        "        max1 = 0\n",
        "        best = -1\n",
        "        for j in range(len(list1)):     \n",
        "            if list1[j] > max1:\n",
        "                max1 = list1[j]\n",
        "                best = j      \n",
        "        list1.remove(max1)\n",
        "        final_list.append(best)      \n",
        "    return final_list\n",
        "\n",
        "# MAKE tSNE GRAPHS\n",
        "# We will load several (N) largest articles, and see if we can cluster paragraphs from the articles by article id\n",
        "# np.random.seed(0)\n",
        "N = 12\n",
        "# indices = np.random.permutation(len(test))[:N]\n",
        "indices = Nmaxelements([len(d['paragraphs']) for d in test], N)\n",
        "articles = [test[i] for i in indices]\n",
        "dataX = []\n",
        "datay = []\n",
        "for a in range(len(articles)):\n",
        "  for p in articles[a]['paragraphs']:\n",
        "    dataX.append(mlp.emb.embed_one_para(p).detach().cpu().numpy())\n",
        "    datay.append(a)\n",
        "dataX = np.stack(dataX, axis=0)\n",
        "datay = np.array(datay)\n",
        "# print(dataX.shape, datay.shape)\n",
        "\n",
        "pca = PCA(n_components=50)\n",
        "pca_result = pca.fit_transform(dataX)\n",
        "\n",
        "time_start = time.time()\n",
        "tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=1000, learning_rate=200.0, init='random')\n",
        "tsne_results = tsne.fit_transform(pca_result)\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "ax1 = plt.subplot(1, 1, 1)\n",
        "plt.title('tSNE Plot by Paragraph Source (Projected FastText)')\n",
        "sns.scatterplot(x=tsne_results[:, 0], y=tsne_results[:, 1], hue=datay,\n",
        "                palette=sns.color_palette(\"hls\", N),\n",
        "                legend=\"auto\", alpha=0.3, ax=ax1)\n",
        "plt.savefig('fasttext.pdf')"
      ],
      "metadata": {
        "id": "aR-ZwB1L94YX"
      },
      "id": "aR-ZwB1L94YX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZNawe-4QdLy"
      },
      "outputs": [],
      "source": [
        "# # investigate distribution of Doc2Vec distributions\n",
        "# def plot_similarity_distribution(similarity=sim, encode=simcse_enc):\n",
        "#     sims = []\n",
        "#     n = len(train_X[0])\n",
        "#     for x in range(n):\n",
        "#         for y in range(x+1,n):\n",
        "#             # print(doc2vec_enc(train_X[0][x]), doc2vec_enc(train_X[0][y]))\n",
        "#             sims.append(similarity(encode(train_X[0][x]), encode(train_X[0][y])))\n",
        "#     plt.hist(sims)\n",
        "#     plt.xlabel('Similarity')\n",
        "#     plt.ylabel('Count')\n",
        "#     plt.show()"
      ],
      "id": "WZNawe-4QdLy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7wFwTidrCH4"
      },
      "outputs": [],
      "source": [
        "# plot_similarity_distribution()"
      ],
      "id": "f7wFwTidrCH4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e49e36c2"
      },
      "source": [
        "##### Training set statistics"
      ],
      "id": "e49e36c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szkFxU2gg_zd"
      },
      "source": [
        "Include stats of  \n",
        "- number of paragraphs per article  \n",
        "- average length of paragraphs per article \n",
        "- maximum depth of articles  "
      ],
      "id": "szkFxU2gg_zd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abf1a160"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt \n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "def getStat(data):\n",
        "    # number of paragraphs per article \n",
        "    num_para = np.array([len(x['paragraphs']) for x in data])\n",
        "    counts, edges, bars = plt.hist(num_para,40)\n",
        "    print(\"========= number of paragraphs per article========\")\n",
        "    print(pd.Series(num_para).describe())\n",
        "    plt.show()\n",
        "    \n",
        "    # number of sentences per paragraph \n",
        "    para_lens = []\n",
        "    for d in data:\n",
        "        paras = d['paragraphs']\n",
        "        for para in paras:\n",
        "            lgh = len(para.split('.'))-1\n",
        "            para_lens.append(lgh)\n",
        "    print(\"========= number of sentences per paragraph========\")\n",
        "    print(pd.Series(para_lens).describe())\n",
        "    _,_,_ = plt.hist(para_lens,40)\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "    # depth of articles \n",
        "    depths = [d['tree'].depth for d in data]\n",
        "    print(\"========= maximum depth of articles========\")\n",
        "    print(pd.Series(depths).describe())\n",
        "    _,_,_ = plt.hist(depths)\n",
        "    plt.show()\n",
        "\n",
        "    return \n",
        "    "
      ],
      "id": "abf1a160"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1e3193c"
      },
      "outputs": [],
      "source": [
        "# getStat(data)"
      ],
      "id": "b1e3193c"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "lQkOcaSmv4v0",
        "0ba86871",
        "PDWF2apsjZT1",
        "HpclBBYffxaL",
        "yc5HGcLzgoFv",
        "e49e36c2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}