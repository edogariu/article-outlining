{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ba86871"
      },
      "source": [
        "##### Load Wikitext dataset (please run!)"
      ],
      "id": "0ba86871"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LbF0QkbhDYL"
      },
      "source": [
        "Headings without any text below it (i.g. only table) are excluded."
      ],
      "id": "8LbF0QkbhDYL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aucLqNev5jNX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "id": "aucLqNev5jNX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfb33fc8"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from datasets import load_dataset, list_datasets\n",
        "import pandas as pd \n",
        "import re \n",
        "import numpy as np "
      ],
      "id": "bfb33fc8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bb659e0"
      },
      "outputs": [],
      "source": [
        "class Node(object):\n",
        "    '''\n",
        "    each node contains \n",
        "    - parent \n",
        "    - children \n",
        "    - text\n",
        "    '''\n",
        "    def __init__(self,txt: str, level:int):\n",
        "        self.text = txt \n",
        "        self.level = level\n",
        "        self.parent = None \n",
        "        self.children = []\n",
        "    def insertChild(self,child):\n",
        "        self.children.append(child)\n",
        "    def linkParent(self, parent):\n",
        "        if(self.parent != None):\n",
        "            print(\"ERROR: node \", self.text, \"already has a parent\")\n",
        "        else:\n",
        "            self.parent = parent \n",
        "            \n",
        "        \n",
        "class Tree(object):\n",
        "    def __init__(self,document):\n",
        "        self.root = Node(document['title'],level=0)\n",
        "        self.depth = np.amax([v['type'] for v in document['document']], initial=0)\n",
        "        curNode = self.root \n",
        "        # para of format {\"text\", \"type\"}\n",
        "        for para in document['document']:\n",
        "            newNode = Node(para['text'],para['type'])\n",
        "            \n",
        "            # growing in depth\n",
        "            if(newNode.level == -1 or newNode.level > curNode.level):\n",
        "                curNode.insertChild(newNode)\n",
        "                newNode.linkParent(curNode)\n",
        "                if(newNode.level > 0):\n",
        "                    curNode = newNode \n",
        "                \n",
        "            # new heading belong to the same or lower level of subheading \n",
        "            else: \n",
        "                # trace back to the heading level that new heading is immediately under \n",
        "                while(curNode.level>=newNode.level):\n",
        "                    curNode = curNode.parent\n",
        "                curNode.insertChild(newNode)\n",
        "                newNode.linkParent(curNode)\n",
        "                curNode = newNode \n",
        "        return \n",
        "    \n",
        "    def printTree(self):\n",
        "        print(\"======== PRINTING TREE =========\")\n",
        "        print(\"TITLE: \", self.root.text)\n",
        "        print(\"MAX DEPTH: \", self.depth)\n",
        "        print(\"===============================\")\n",
        "        def printNode(curNode):\n",
        "            print(curNode.text)\n",
        "            if(curNode.level == -1):\n",
        "                return \n",
        "            \n",
        "            for child in curNode.children:\n",
        "                printNode(child)\n",
        "            return \n",
        "        printNode(self.root)\n",
        "        \n",
        "    \n",
        "\n",
        "        "
      ],
      "id": "3bb659e0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f09a8de0"
      },
      "outputs": [],
      "source": [
        "## helper functions \n",
        "\n",
        "# get type of text \n",
        "def checkHeading(txt):\n",
        "    if(txt == ''):\n",
        "        return -2\n",
        "    if(re.search(r'^\\s=.+\\s=\\s\\n',txt)):\n",
        "        return int(len(re.findall(r'\\s=',txt))/2 - 1)\n",
        "    return -1 \n",
        "\n",
        "# load documents to feed to tree \n",
        "def createDocuments(data):\n",
        "    documents_with = []\n",
        "    documents_without = []\n",
        "    document_with = []\n",
        "    document_without = []\n",
        "    curTitle = ''\n",
        "    for i in data:\n",
        "        c = checkHeading(i)\n",
        "        if(c==-2):\n",
        "            continue\n",
        "        if(c>-1):\n",
        "            # strip heading \n",
        "            i = re.findall(r'=\\s([^=]+)\\s=', i)[0]\n",
        "        if(c==0):\n",
        "            \n",
        "            # clear out empty headings \n",
        "            while(len(document_with)>1 and document_with[-1]['type']!=-1):\n",
        "                document_with.pop(-1)\n",
        "            documents_with.append({'title': curTitle, 'document':document_with})\n",
        "            documents_without.append(document_without)\n",
        "            curTitle = i\n",
        "            document_with = []\n",
        "            document_without = []\n",
        "            \n",
        "        else:\n",
        "            # clear out empty headings GOOFY HELP HOW TO CLEAN THIS UP \n",
        "            if(len(document_with)>1 and document_with[-1]['type']!=-1 and c <= document_with[-1]['type'] and c!=-1):\n",
        "                document_with.pop(-1)\n",
        "            document_with.append({'text':i,'type':c})\n",
        "            if(c==-1):\n",
        "                document_without.append(i)\n",
        "            \n",
        "    documents_with.pop(0)\n",
        "    documents_without.pop(0)\n",
        "    return documents_with, documents_without"
      ],
      "id": "f09a8de0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7ac6222"
      },
      "source": [
        "loadData() creates a list of data points containing the title of article, raw text (paragraphs), and the tree representation of heading structures."
      ],
      "id": "e7ac6222"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6f4ecfe"
      },
      "outputs": [],
      "source": [
        "## load wiki dataset \n",
        "def loadData(train = False, min_size=-1):\n",
        "    \"\"\"\n",
        "    prepare dataset for training, which is a list of dictionaries containing:  \n",
        "    - document title (string)\n",
        "    - paragraphs (list of string)\n",
        "    - tree representation of headings\n",
        "    \"\"\"\n",
        "    \n",
        "    data_raw = load_dataset(\"wikitext\",'wikitext-103-v1',split='train' if train else 'test')\n",
        "    data_raw = data_raw['text']\n",
        "    documents_with, documents_without = createDocuments(data_raw)\n",
        "    \n",
        "    data = []\n",
        "    i = 0\n",
        "    for document in documents_with:\n",
        "        tree = Tree(document)\n",
        "        if len(documents_without[i]) < min_size:\n",
        "          continue\n",
        "#         tree.printTree()\n",
        "        data.append({\n",
        "            \"title\":document['title'],\n",
        "            \"paragraphs\":documents_without[i],\n",
        "            \"tree\": tree\n",
        "        })\n",
        "        i+=1\n",
        "    return data    "
      ],
      "id": "e6f4ecfe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de5fbda0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "data = loadData(train=True)"
      ],
      "id": "de5fbda0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48ec35e7"
      },
      "source": [
        "testing: compared tree pre-order traversal of 10 documents with raw data. No bug. "
      ],
      "id": "48ec35e7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e49e36c2"
      },
      "source": [
        "##### Training set statistics"
      ],
      "id": "e49e36c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szkFxU2gg_zd"
      },
      "source": [
        "Include stats of  \n",
        "- number of paragraphs per article  \n",
        "- average length of paragraphs per article \n",
        "- maximum depth of articles  "
      ],
      "id": "szkFxU2gg_zd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abf1a160"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt \n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "def getStat(data):\n",
        "    # number of paragraphs per article \n",
        "    num_para = np.array([len(x['paragraphs']) for x in data])\n",
        "    counts, edges, bars = plt.hist(num_para,40)\n",
        "    print(\"========= number of paragraphs per article========\")\n",
        "    print(pd.Series(num_para).describe())\n",
        "    plt.show()\n",
        "    \n",
        "    # number of sentences per paragraph \n",
        "    para_lens = []\n",
        "    for d in data:\n",
        "        paras = d['paragraphs']\n",
        "        for para in paras:\n",
        "            lgh = len(para.split('.'))-1\n",
        "            para_lens.append(lgh)\n",
        "    print(\"========= number of sentences per paragraph========\")\n",
        "    print(pd.Series(para_lens).describe())\n",
        "    _,_,_ = plt.hist(para_lens,40)\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "    # depth of articles \n",
        "    depths = [d['tree'].depth for d in data]\n",
        "    print(\"========= maximum depth of articles========\")\n",
        "    print(pd.Series(depths).describe())\n",
        "    _,_,_ = plt.hist(depths)\n",
        "    plt.show()\n",
        "\n",
        "    return \n",
        "    "
      ],
      "id": "abf1a160"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1e3193c"
      },
      "outputs": [],
      "source": [
        "getStat(data)"
      ],
      "id": "b1e3193c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSKtCnA_BdMD"
      },
      "source": [
        "##### Preparing SimCSE and Doc2Vec embeddings + related setup (please run!)"
      ],
      "id": "FSKtCnA_BdMD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qkh6gZxswMUB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import random\n",
        "random.seed(10)\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "from IPython.utils import io"
      ],
      "id": "Qkh6gZxswMUB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87baa622"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install simcse"
      ],
      "id": "87baa622"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szpU2OFCB3s0"
      },
      "outputs": [],
      "source": [
        "from simcse import SimCSE\n",
        "simcse_model = SimCSE(\"princeton-nlp/sup-simcse-bert-base-uncased\")"
      ],
      "id": "szpU2OFCB3s0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP43IO_uB3wn"
      },
      "outputs": [],
      "source": [
        "# # mini-demo with print suppression\n",
        "# with io.capture_output() as captured:\n",
        "#     print('this should not be printed')\n",
        "#     embeddings = simcse_model.encode(\"A woman is reading, and a man is here\")\n",
        "# print('this should be printed')\n",
        "# print(embeddings.shape)"
      ],
      "id": "mP43IO_uB3wn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmqyWpNGmruU"
      },
      "outputs": [],
      "source": [
        "SIMCSE_DIM = 768\n",
        "MAX_DEPTH = 8\n",
        "# MAX_PARAS = 300\n",
        "# MAX_SENTS_PER_PARA = 80"
      ],
      "id": "zmqyWpNGmruU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThJG0MPafOBW"
      },
      "outputs": [],
      "source": [
        "# for segmentation\n",
        "START_IDX = 0\n",
        "END_IDX = MAX_DEPTH"
      ],
      "id": "ThJG0MPafOBW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NiXOdkJHcI5"
      },
      "outputs": [],
      "source": [
        "!pip install gensim==4.1.2\n",
        "!pip install cython\n",
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "id": "0NiXOdkJHcI5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBFAl4oVXTj5"
      },
      "source": [
        "Train Doc2Vec Encoder (only done once, after that we load from 'd2v.model')"
      ],
      "id": "xBFAl4oVXTj5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb6rnfyOH7jv"
      },
      "outputs": [],
      "source": [
        "# # DONT NEED TO RUN THIS CELL IF U HAVE THE FILES\n",
        "# documents = [d['paragraphs'] for d in data]\n",
        "# paragraphs = []\n",
        "# for doc in documents:\n",
        "#   for p in doc:\n",
        "#     paragraphs.append(p)\n",
        "# # print(len(paragraphs))\n",
        "# tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(paragraphs)]\n",
        "\n",
        "\n",
        "# max_epochs = 15\n",
        "# vec_size = 128\n",
        "# alpha = 0.025\n",
        "\n",
        "# with io.capture_output() as captured:\n",
        "#     doc2vec_model = Doc2Vec(vector_size=128, min_count=2, window=2, workers=4, dm=1, alpha=alpha, min_alpha=0.00025)\n",
        "#     doc2vec_model.build_vocab(tagged_data)\n",
        "\n",
        "# for epoch in range(max_epochs):\n",
        "#     print('iteration {0}'.format(epoch))\n",
        "#     with io.capture_output() as captured:\n",
        "#         doc2vec_model.train(tagged_data,\n",
        "#                             total_examples=doc2vec_model.corpus_count,\n",
        "#                             epochs=4)\n",
        "#     # decrease the learning rate\n",
        "#     doc2vec_model.alpha -= 0.0002\n",
        "#     # fix the learning rate, no decay\n",
        "#     doc2vec_model.min_alpha = doc2vec_model.alpha\n",
        "\n",
        "# doc2vec_model.save(\"d2v.model\")\n"
      ],
      "id": "zb6rnfyOH7jv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANF-NCtImfWz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "ANF-NCtImfWz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9GjBog-n4k4"
      },
      "source": [
        "Make sure to add 484-finalProject as shortcut in drive."
      ],
      "id": "d9GjBog-n4k4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxT9-NNFmvTL"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/My\\ Drive/484-finalProject"
      ],
      "id": "jxT9-NNFmvTL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04k_YJCVBigD"
      },
      "outputs": [],
      "source": [
        "doc2vec_model= Doc2Vec.load(\"models/128_d2v.model\")"
      ],
      "id": "04k_YJCVBigD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E12J-l2eXiM-"
      },
      "outputs": [],
      "source": [
        "# # Experiment with inference and lookups :)\n",
        "# test1 = word_tokenize(\"This is a test of the paragraph embedding model.\".lower())\n",
        "# test2 = word_tokenize(\"I am testing my model to encode paragraphs.\".lower())\n",
        "# test3 = word_tokenize(\"Complete gibberish, baby talk with a model. Goo goo ga ga.\")\n",
        "# test4 = word_tokenize(\"This is a test for my model to embed paragraphs.\".lower())\n",
        "\n",
        "# v = doc2vec_model.infer_vector(test1)\n",
        "# v1 = doc2vec_model.infer_vector(test1)\n",
        "# v2 = doc2vec_model.infer_vector(test2)\n",
        "# v3 = doc2vec_model.infer_vector(test3)\n",
        "# v4 = doc2vec_model.infer_vector(test4)\n",
        "# print(np.linalg.norm(v1 - v))  # normal inference, turns tokenized, lowercase paragraph into 128-vector\n",
        "# print(np.linalg.norm(v1 - v2)) \n",
        "# print(np.linalg.norm(v1 - v3))\n",
        "# print(np.linalg.norm(v1 - v4))\n",
        "# print()\n",
        "\n",
        "# print(np.dot(v1, v)/(np.linalg.norm(v1)*np.linalg.norm(v)))  # normal inference, turns tokenized, lowercase paragraph into 128-vector\n",
        "# print(np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2)))\n",
        "# print(np.dot(v1, v3)/(np.linalg.norm(v1)*np.linalg.norm(v3)))\n",
        "# print(np.dot(v1, v4)/(np.linalg.norm(v1)*np.linalg.norm(v4)))\n",
        "\n",
        "# print()\n",
        "# print(doc2vec_model.similarity_unseen_docs(test, test4))\n",
        "\n",
        "# # print(doc2vec_model.dv['2'])  # dictionary where each paragraph embedding has a numbered id"
      ],
      "id": "E12J-l2eXiM-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1byrFPm5do8S"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "id": "1byrFPm5do8S"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDWF2apsjZT1"
      },
      "source": [
        "##### Preparing LCA loss evaluation function + tools for trees (please run!)"
      ],
      "id": "PDWF2apsjZT1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBXXXBS4jjcT"
      },
      "outputs": [],
      "source": [
        "# tree-related helper functions\n",
        "\n",
        "# iterate over a tree rooted at node in preorder traversal\n",
        "def preorder(node):\n",
        "    if len(node.children) == 0:\n",
        "        yield node\n",
        "    for ch in node.children:\n",
        "        yield from preorder(ch)\n",
        "\n",
        "# only prints leaves, i.e. text representations of paragraph\n",
        "# note: depends on accurate text, level population\n",
        "# text should be indices\n",
        "def print_tree(curNode):\n",
        "    if curNode.level == -1:\n",
        "        print(curNode.text, end='')\n",
        "        return\n",
        "    print('[', end='')\n",
        "    for idx, child in enumerate(curNode.children):\n",
        "        print_tree(child)\n",
        "        if idx < len(curNode.children) - 1:\n",
        "            print(', ', end='')\n",
        "    print(']', end='')\n",
        "    if curNode.level == 0:\n",
        "        print() # final print after entire tree is printed\n",
        "\n",
        "# text should be snippets\n",
        "def print_snippet_tree(curNode, indent='  '):\n",
        "    if curNode.level == -1:\n",
        "        print(indent + curNode.text, end='')\n",
        "        return\n",
        "    print(indent+'[heading]')\n",
        "    for idx, child in enumerate(curNode.children):\n",
        "        print_snippet_tree(child, indent+'  ')\n",
        "        if idx < len(curNode.children) - 1:\n",
        "            print()\n",
        "    if curNode.level == 0:\n",
        "        print() # final print after entire tree is printed\n",
        "\n",
        "def clone_tree(root):\n",
        "    root_copy = Node(root.text, root.level)\n",
        "    for ch in root.children:\n",
        "        root_copy.insertChild(clone_tree(ch))\n",
        "        root_copy.children[-1].linkParent(root_copy)\n",
        "    return root_copy\n",
        "\n",
        "# return indexified tree with text as paragraphs to text as indices of paragraphs for more concise printing\n",
        "def indexified_tree(root):\n",
        "    root_copy = clone_tree(root)\n",
        "    for idx, node in enumerate(preorder(root_copy)):\n",
        "        node.text = idx\n",
        "    return root_copy\n",
        "\n",
        "# return indexified tree with text as paragraphs to text as indices of paragraphs for more concise printing\n",
        "def textified_tree(root, paras):\n",
        "    root_copy = clone_tree(root)\n",
        "    for idx, node in enumerate(preorder(root_copy)):\n",
        "        node.text = paras[idx][:40] + '...'\n",
        "    return root_copy\n",
        "\n",
        "# print_tree(roots[0])\n",
        "# print_tree(train_y[0].root)"
      ],
      "id": "IBXXXBS4jjcT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9hZqeHXjef7"
      },
      "outputs": [],
      "source": [
        "# lca-related helper functions and lca loss\n",
        "# note: assumed indexified trees\n",
        "def trace_helper(node, i, trace):\n",
        "    if node.text == i:\n",
        "        return True\n",
        "    for idx, ch in enumerate(node.children):\n",
        "        if trace_helper(ch, i, trace):\n",
        "            trace.append(idx)\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def get_trace(root, i):\n",
        "    trace = []\n",
        "    trace_helper(root, i, trace)\n",
        "    trace.reverse()\n",
        "    return trace\n",
        "\n",
        "def compute_lca_dist(root, i, j):\n",
        "    trace_i = get_trace(root, i)\n",
        "    trace_j = get_trace(root, j)\n",
        "    # print(trace_i)\n",
        "    # print(trace_j)\n",
        "    for idx in range(min(len(trace_i), len(trace_j))):\n",
        "        if trace_i[idx] != trace_j[idx]:\n",
        "            return len(trace_i) + len(trace_j) - 2 * idx\n",
        "    return len(trace_i) + len(trace_j)\n",
        "\n",
        "def lca_loss(root1, root2, num_paras):\n",
        "    loss = 0\n",
        "    for i in range(2, num_paras+1): # 1-indexed from indexify\n",
        "        j = i-1\n",
        "        dist1 = compute_lca_dist(root1, i, j)\n",
        "        dist2 = compute_lca_dist(root2, i, j)\n",
        "        # print(i, j, dist1, dist2)\n",
        "        loss += (dist1 - dist2) * (dist1 - dist2)\n",
        "    if num_paras == 1:\n",
        "        return loss\n",
        "    return loss / (num_paras - 1)\n",
        "\n",
        "# def lca_loss(root1, root2, num_paras):\n",
        "#     loss = 0\n",
        "#     for i in range(1, num_paras+1): # 1-indexed from indexify\n",
        "#         for j in range(i+1, num_paras+1):\n",
        "#             dist1 = compute_lca_dist(root1, i, j)\n",
        "#             dist2 = compute_lca_dist(root2, i, j)\n",
        "#             # print(i, j, dist1, dist2)\n",
        "#             loss += (dist1 - dist2) * (dist1 - dist2)\n",
        "#     if num_paras == 1:\n",
        "#         return loss\n",
        "#     return loss / num_paras / (num_paras - 1) * 2\n",
        "\n",
        "def batch_lca_loss(roots1, roots2, num_paras):\n",
        "    tt = 0\n",
        "    for root1, root2, num in zip(roots1, roots2, num_paras):\n",
        "        tt += lca_loss(root1, root2, num)\n",
        "    return tt / len(roots1)"
      ],
      "id": "z9hZqeHXjef7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_aNj3_bh9VG"
      },
      "source": [
        "##### Model 1: End-to-end -- note this code may be behind the local version on Evan's big boi computer"
      ],
      "id": "X_aNj3_bh9VG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FDvqg_Xi2mR"
      },
      "source": [
        "Approach: SimCSE/Doc2Vec + bidirectional LSTM + transformer -> segmentations"
      ],
      "id": "2FDvqg_Xi2mR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OatKuhkFCEcQ"
      },
      "outputs": [],
      "source": [
        "class HeaderNet(nn.Module):\n",
        "    def __init__(self, hid_dim=32, n_layers=1, num_heads=4, # CURRENTLY ONLY SUPPROTS N_LAYERS=1\n",
        "                 num_enc_layers=1, num_dec_layers=1, ff_dim=1024, dropout=0.1, output_dim=2*MAX_DEPTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.num_heads = num_heads\n",
        "        self.num_enc_layers = num_enc_layers\n",
        "        self.num_dec_layers = num_dec_layers\n",
        "        self.ff_dim = ff_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.lstm = nn.LSTM(SIMCSE_DIM,\n",
        "                            hid_dim,\n",
        "                            num_layers=n_layers,\n",
        "                            bidirectional=True,\n",
        "                            batch_first=True)\n",
        "        self.transformer = nn.Transformer(d_model=hid_dim*4, nhead=num_heads, num_encoder_layers=num_enc_layers,\n",
        "                                          num_decoder_layers=num_dec_layers, dim_feedforward=ff_dim, dropout=dropout, batch_first=True)\n",
        "        self.linear = nn.Linear(hid_dim*4, output_dim)\n",
        "\n",
        "    # masks for transformer to account for variable numbers of paragraphs per article\n",
        "    def compute_len_masks(self, batch):\n",
        "        lens = [len(text) for text in batch]\n",
        "        max_num_paras = max(lens)\n",
        "        len_masks = torch.zeros(len(batch), max_num_paras)\n",
        "        for idx, text_len in enumerate(lens):\n",
        "            len_masks[idx, text_len:] = 1\n",
        "        return lens, len_masks.to(self.device)\n",
        "\n",
        "    # compute sentence embeddings from paragraphs in text\n",
        "    def compute_sentence_embeddings(self, batch):\n",
        "        num_para = [len(x) for x in batch]\n",
        "        batch_para = []\n",
        "\n",
        "        # build list of lists of sentence embeddings\n",
        "        # note that num paragraphs and num sentences are both variable\n",
        "        sents_emb = []\n",
        "        for text in batch:\n",
        "            for para in text:\n",
        "                para = re.sub('\\n', '', para)\n",
        "                sents = re.split('[.]|[!]|[?]', para.strip())\n",
        "                with io.capture_output() as captured:\n",
        "                    sents_emb_i = simcse_model.encode(sents, device=self.device, batch_size=len(sents))\n",
        "                sents_emb.append(sents_emb_i)\n",
        "        return sents_emb\n",
        "\n",
        "    # returns a list of slices along the first dim according to a given list of slice lengths\n",
        "    def partition(self, data, lens):\n",
        "        data_list = []\n",
        "        idx = 0\n",
        "        for len_i in lens:\n",
        "            data_list.append(data[idx:idx+len_i])\n",
        "            idx += len_i\n",
        "        return data_list\n",
        "\n",
        "    def forward(self, batch):\n",
        "        # compute len masks\n",
        "        lens, len_masks = self.compute_len_masks(batch)\n",
        "\n",
        "        # # paragraphs -> sentence embeddings\n",
        "        # sents_emb = self.compute_sentence_embeddings(batch)\n",
        "        # sent_lens = [x.shape[0] for x in sents_emb]\n",
        "        # sents_emb = torch.nn.utils.rnn.pad_sequence(sents_emb, batch_first=True).to(device)\n",
        "        # packed_in = torch.nn.utils.rnn.pack_padded_sequence(sents_emb, sent_lens, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # # sentence embeddings -> paragraph embeddings\n",
        "        # packed_out, (hidden, cell) = self.lstm(packed_in.to(self.device))\n",
        "        # para_emb = torch.cat((hidden[0], cell[0], hidden[1], cell[1]), dim=1)\n",
        "        # para_list = self.partition(para_emb, lens) # group paragraph embeddings by article\n",
        "        # print(len(para_list))\n",
        "        # print(para_list[0].shape)\n",
        "        # text_emb = torch.nn.utils.rnn.pad_sequence(para_list, batch_first=True).to(device)\n",
        "        \n",
        "        \n",
        "        para_list = []\n",
        "        for article in batch:\n",
        "          para_list.append(torch.stack([torch.tensor(doc2vec_model.infer_vector(word_tokenize(p.lower())), device=device) for p in article], dim=0))\n",
        "        text_emb = torch.nn.utils.rnn.pad_sequence(para_list, batch_first=True).to(device)\n",
        "        \n",
        "        # paragraph embeddings -> outlines\n",
        "        logits = self.transformer(text_emb, text_emb, src_key_padding_mask=len_masks, tgt_key_padding_mask=len_masks)\n",
        "        logits = logits[len_masks == 0]\n",
        "        logits = self.linear(logits)\n",
        "        logit_list = self.partition(logits, lens)\n",
        "        \n",
        "        return logit_list\n",
        "\n",
        "    @property\n",
        "    def device(self) -> torch.device:\n",
        "        \"\"\" Determine which device to place the Tensors upon, CPU or GPU.\n",
        "        \"\"\"\n",
        "        return device\n",
        "    \n",
        "    @staticmethod\n",
        "    def load(model_path: str):\n",
        "        \"\"\" Load the model from a file.\n",
        "        @param model_path (str): path to model\n",
        "        \"\"\"\n",
        "        params = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "        args = params['args']\n",
        "        model = HeaderNet(**args)\n",
        "        model.load_state_dict(params['state_dict'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def save(self, path: str):\n",
        "        \"\"\" Save the model to a file.\n",
        "        @param path (str): path to the model\n",
        "        \"\"\"\n",
        "\n",
        "        params = {\n",
        "            'args': dict(hid_dim=self.hid_dim, n_layers=self.n_layers, num_heads=self.num_heads,\n",
        "                 num_enc_layers=self.num_enc_layers, num_dec_layers=self.num_dec_layers, ff_dim=self.ff_dim, dropout=self.dropout),\n",
        "            'state_dict': self.state_dict()\n",
        "        }\n",
        "\n",
        "        torch.save(params, path)"
      ],
      "id": "OatKuhkFCEcQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qnZNERGsYn_"
      },
      "outputs": [],
      "source": [
        "# # encode just the depths -- note that this is insufficient to reconstruct the tree\n",
        "# def add_tree_depths(node, depths, cur_depth):\n",
        "#     if node.level == -1: # this is paragraph node, not a heading\n",
        "#         depths.append(cur_depth)\n",
        "#         return\n",
        "#     for child in node.children:\n",
        "#         add_tree_depths(child, depths, cur_depth+1)\n",
        "\n",
        "# def get_depths(trees, one_hot=True):\n",
        "#     depths = []\n",
        "#     for tree in trees:\n",
        "#         depths_i = []\n",
        "#         add_tree_depths(tree.root, depths_i, 0)\n",
        "#         if one_hot:\n",
        "#             depths.append(F.one_hot(torch.tensor(depths_i), num_classes=MAX_DEPTH))\n",
        "#         else:\n",
        "#             depths.append(torch.tensor(depths_i))\n",
        "#     return torch.stack(depths, dim=0)\n",
        "\n",
        "# encode outlines\n",
        "# note: we use 0 as padding symbol\n",
        "def add_tree_outlines(node, outlines, cur_outline):\n",
        "    if node.level == -1: # this is paragraph node, not a heading\n",
        "        outlines.append(torch.clone(cur_outline))\n",
        "        return\n",
        "    for child in node.children:\n",
        "        cur_outline[node.level] += 1\n",
        "        add_tree_outlines(child, outlines, cur_outline)\n",
        "    cur_outline[node.level] = 0\n",
        "\n",
        "def get_outlines(paras, trees):\n",
        "    max_paras = max([len(x) for x in paras])\n",
        "    outlines = []\n",
        "    for tree in trees:\n",
        "        outlines_i = []\n",
        "        add_tree_outlines(tree.root, outlines_i, torch.zeros(MAX_DEPTH))\n",
        "        outlines_i = torch.stack(outlines_i, dim=0).to(device)\n",
        "        outlines.append(outlines_i)\n",
        "    return outlines\n",
        "\n",
        "# encode breaks\n",
        "\n",
        "def add_tree_segs(node, outlines, cur_outline):\n",
        "    if node.level == -1: # this is paragraph node, not a heading\n",
        "        outlines.append(torch.clone(cur_outline))\n",
        "        return\n",
        "    for child in node.children:\n",
        "        if child == node.children[0]: # first entry\n",
        "            cur_outline[START_IDX + node.level] = 1\n",
        "        if child == node.children[-1]:\n",
        "            cur_outline[END_IDX + node.level] = 1\n",
        "        add_tree_segs(child, outlines, cur_outline)\n",
        "        if child == node.children[0]:\n",
        "            cur_outline[START_IDX + node.level] = 0\n",
        "        if child == node.children[-1]:\n",
        "            cur_outline[END_IDX + node.level] = 0\n",
        "    cur_outline[node.level+1] = 0\n",
        "\n",
        "def get_segs(paras, trees):\n",
        "    max_paras = max([len(x) for x in paras])\n",
        "    outlines = []\n",
        "    for tree in trees:\n",
        "        outlines_i = []\n",
        "        add_tree_segs(tree.root, outlines_i, torch.zeros(2*MAX_DEPTH))\n",
        "        outlines_i = torch.stack(outlines_i, dim=0).to(device)\n",
        "        outlines.append(outlines_i)\n",
        "    return outlines"
      ],
      "id": "_qnZNERGsYn_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyhj2RhkGsXl"
      },
      "outputs": [],
      "source": [
        "# test demo\n",
        "# model = HeaderNet()\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print('use device: %s' % device)\n",
        "# model = model.to(device)\n",
        "# y_hat = model(train_X[0:5])\n",
        "# y = get_outlines(train_X[0:5], train_y[0:5])"
      ],
      "id": "eyhj2RhkGsXl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH-fMeW-oydJ"
      },
      "outputs": [],
      "source": [
        "def get_paragraphs_trees(data):\n",
        "    paras = [d['paragraphs'] for d in data]\n",
        "    trees = [d['tree'] for d in data]\n",
        "    return paras, trees\n",
        "\n",
        "def get_split_data(data, train_ratio=0.05, val_ratio=0.001, test_ratio=0.002):\n",
        "    random.shuffle(data)\n",
        "    n_data = len(data)\n",
        "    train_idx = int(train_ratio*n_data)\n",
        "    val_idx = int((train_ratio + val_ratio)*n_data)\n",
        "    test_idx = int((train_ratio + val_ratio + test_ratio)*n_data)\n",
        "    train_X, train_y = get_paragraphs_trees(data[:train_idx])\n",
        "    val_X, val_y = get_paragraphs_trees(data[train_idx:val_idx])\n",
        "    test_X, test_y = get_paragraphs_trees(data[val_idx:test_idx])\n",
        "    return train_X, train_y, val_X, val_y, test_X, test_y"
      ],
      "id": "QH-fMeW-oydJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RKkK93gqanM"
      },
      "outputs": [],
      "source": [
        "train_X, train_y, val_X, val_y, test_X, test_y = get_split_data(data)"
      ],
      "id": "2RKkK93gqanM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGLH3oYgIUoC"
      },
      "outputs": [],
      "source": [
        "train_reshaped = torch.cat(get_segs(train_X, train_y), dim=0)\n",
        "train_mean = torch.mean(train_reshaped, dim=0)\n",
        "train_std = torch.std(train_reshaped, dim=0)\n",
        "train_std += 1e-6 # deal with div by zero\n",
        "def normalize(segs):\n",
        "    normed_segs = []\n",
        "    for s in segs:\n",
        "        normed_segs.append(torch.div(torch.sub(s, train_mean), train_std))\n",
        "    return normed_segs"
      ],
      "id": "YGLH3oYgIUoC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8J51HNFJFjG"
      },
      "outputs": [],
      "source": [
        "# # testing normalize\n",
        "# segs = get_segs(train_X, train_y)\n",
        "# normed_segs = normalize(get_segs(train_X, train_y))\n",
        "\n",
        "# v_segs = get_segs(val_X, val_y)\n",
        "# v_normed_segs = normalize(get_segs(val_X, val_y))\n",
        "\n",
        "# print(torch.mean(torch.cat(segs),dim=0))\n",
        "# print(torch.mean(torch.cat(normed_segs),dim=0))\n",
        "# print(torch.std(torch.cat(segs),dim=0))\n",
        "# print(torch.std(torch.cat(normed_segs),dim=0))\n",
        "\n",
        "# print(torch.mean(torch.cat(v_segs),dim=0))\n",
        "# print(torch.mean(torch.cat(v_normed_segs),dim=0))\n",
        "# print(torch.std(torch.cat(v_segs),dim=0))\n",
        "# print(torch.std(torch.cat(v_normed_segs),dim=0))"
      ],
      "id": "x8J51HNFJFjG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZZo91Uglvx_"
      },
      "outputs": [],
      "source": [
        "# iterate over batches of data and labels\n",
        "# articles in batch are sorted by descending num paragraphs for efficient packing/LSTM inference\n",
        "def batch_iter(data, labels, batch_size, shuffle=False):\n",
        "    batch_num = math.ceil(len(data) / batch_size)\n",
        "    index_array = list(range(len(data)))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.shuffle(index_array)\n",
        "\n",
        "    for i in range(batch_num):\n",
        "        indices = index_array[i * batch_size: (i + 1) * batch_size]\n",
        "        indices = sorted(indices, key=lambda idx: len(data[idx]), reverse=True)\n",
        "        batch_data = [data[idx] for idx in indices]\n",
        "        batch_labels = [labels[idx] for idx in indices]\n",
        "\n",
        "        yield batch_data, batch_labels"
      ],
      "id": "CZZo91Uglvx_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zQERFHtdJxK"
      },
      "outputs": [],
      "source": [
        "def outline_loss(y_hat, y, output_format='segmentation'):\n",
        "    tt_loss = torch.tensor([0.0]).to(device)\n",
        "    if output_format == 'segmentation':\n",
        "        weights = [128, 64, 32, 16, 8, 4, 2, 1, 128, 64, 32, 16, 8, 4, 2, 1]\n",
        "    elif output_format == 'outlines':\n",
        "        weights = [128, 64, 32, 16, 8, 4, 2, 1]\n",
        "    for y_hat_i, y_i in zip(y_hat, y):\n",
        "        loss_weights = torch.tensor(weights).to(device).repeat(y_i.shape[0], 1) # exponentially weight higher level headings more\n",
        "        tt_loss += (torch.square(y_hat_i - y_i)).mul(loss_weights).mean()\n",
        "    return tt_loss / len(y)"
      ],
      "id": "6zQERFHtdJxK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwySi2ltkv-1"
      },
      "outputs": [],
      "source": [
        "def train(train_X, train_y, val_X, val_y, lr=0.002, batch_size=32, grad_clip=5.0, lr_decay=0.5,\n",
        "          max_epoch=50, log_every=5, valid_niter=75, max_patience=4, max_num_trial=5, model_path='model.bin'):\n",
        "    model = HeaderNet()\n",
        "    model.train()\n",
        "\n",
        "    # # initialize model parameters\n",
        "    # for p in model.parameters():\n",
        "    #     p.data.uniform_(-0.1, 0.1)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('use device: %s' % device)\n",
        "\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    print('{} parameters!'.format(sum([np.prod(p.size()) for p in model_parameters])))\n",
        "\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "\n",
        "    num_trial = 0\n",
        "    train_iter = patience = cum_loss = report_loss = cum_tgt_words = report_tgt_words = 0\n",
        "    cum_examples = report_examples = epoch = valid_num = 0\n",
        "    hist_valid_scores = []\n",
        "    train_time = begin_time = time.time()\n",
        "    print('begin Maximum Likelihood training')\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    while True:\n",
        "        epoch += 1\n",
        "        batch_num = math.ceil(len(train_X) / batch_size)\n",
        "        current_iter = 0\n",
        "        for examples, labels in batch_iter(train_X, train_y, batch_size=batch_size, shuffle=True):\n",
        "            model.train()\n",
        "            current_iter += 1\n",
        "            train_iter += 1\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            batch_size = len(examples)\n",
        "            train_loss = outline_loss(model(examples), get_segs(examples, labels))\n",
        "            train_loss.backward()\n",
        "\n",
        "            # clip gradient\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            report_loss += train_loss\n",
        "            cum_loss += train_loss\n",
        "            report_examples += batch_size\n",
        "            cum_examples += batch_size\n",
        "\n",
        "            if train_iter % log_every == 0:\n",
        "                print('epoch %d (%d / %d), iter %d, avg train loss %.2f, '\n",
        "                      'cum examples %d, time elapsed %.2f sec' %\n",
        "                      (epoch, current_iter, batch_num, train_iter,\n",
        "                       report_loss / report_examples,\n",
        "                       cum_examples,\n",
        "                       time.time() - begin_time))\n",
        "\n",
        "                train_time = time.time()\n",
        "                report_loss = report_examples = 0.\n",
        "\n",
        "            # perform validation\n",
        "            if train_iter % valid_niter == 0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    print('epoch %d, iter %d, cum loss %.2f, cum examples %d' % (epoch, train_iter,\n",
        "                            cum_loss / cum_examples,\n",
        "                            cum_examples))\n",
        "                    train_losses.append(cum_loss / cum_examples)\n",
        "                    cum_loss = cum_examples = 0.\n",
        "\n",
        "                    print('begin validation ...')\n",
        "\n",
        "                    val_cum_loss = 0\n",
        "                    val_cum_examples = 0\n",
        "\n",
        "                    count = 0\n",
        "                    NUM_BATCHES = 16  # number of batches to validate over each time\n",
        "                    for e, l in batch_iter(val_X, val_y, batch_size, shuffle=True):\n",
        "                        if count >= NUM_BATCHES:\n",
        "                            break\n",
        "                        batch_size = len(e)\n",
        "                        val_loss = outline_loss(model(e), get_segs(e, l))\n",
        "                        val_cum_loss += val_loss\n",
        "                        val_cum_examples += batch_size\n",
        "                        count += 1\n",
        "\n",
        "                    val_losses.append(val_cum_loss / val_cum_examples)\n",
        "                    valid_metric = -val_cum_loss / val_cum_examples # metric for evaluating whether model is improving on val data\n",
        "\n",
        "                    print('validation: iter %d, val loss %f' % (train_iter, val_loss))\n",
        "\n",
        "                    is_better = len(hist_valid_scores) == 0 or valid_metric > max(hist_valid_scores)\n",
        "                    hist_valid_scores.append(valid_metric)\n",
        "\n",
        "                    if is_better:\n",
        "                        patience = 0\n",
        "                        print('epoch %d, iter %d: save currently the best model to [%s]' %\n",
        "                                (epoch, train_iter, model_path))\n",
        "                        model.save(model_path)\n",
        "                        torch.save(optimizer.state_dict(), model_path + '.optim')\n",
        "                        np.save('train.npy', np.array(train_losses))\n",
        "                        np.save('val.npy', np.array(val_losses))\n",
        "                    elif patience < max_patience:\n",
        "                        patience += 1\n",
        "                        print('hit patience %d' % patience)\n",
        "\n",
        "                        if patience == max_patience:\n",
        "                            num_trial += 1\n",
        "                            print('hit #%d trial' % num_trial)\n",
        "                            if num_trial == max_num_trial:\n",
        "                                print('early stop!')\n",
        "                                exit(0)\n",
        "\n",
        "                            # decay lr, and restore from previously best checkpoint\n",
        "                            lr = optimizer.param_groups[0]['lr'] * lr_decay\n",
        "                            print('load previously best model and decay learning rate to %f' % lr)\n",
        "\n",
        "                            # load model\n",
        "                            params = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "                            model.load_state_dict(params['state_dict'])\n",
        "                            model = model.to(device)\n",
        "                            train_losses = list(np.load('train.npy'))\n",
        "                            val_losses = list(np.load('val.npy'))\n",
        "\n",
        "                            print('restore parameters of the optimizers')\n",
        "                            optimizer.load_state_dict(torch.load(model_path + '.optim'))\n",
        "\n",
        "                            # set new lr\n",
        "                            for param_group in optimizer.param_groups:\n",
        "                                param_group['lr'] = lr\n",
        "\n",
        "                            # reset patience\n",
        "                            patience = 0\n",
        "\n",
        "        if epoch == max_epoch:\n",
        "            print('reached maximum number of epochs!')\n",
        "            break"
      ],
      "id": "lwySi2ltkv-1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PVB2pZ9k2it"
      },
      "outputs": [],
      "source": [
        "train(train_X, train_y, val_X, val_y)"
      ],
      "id": "1PVB2pZ9k2it"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkmXINGAoG2B"
      },
      "outputs": [],
      "source": [
        "# print(data[0]['tree'].depth)\n",
        "# print(data[0]['title'])\n",
        "# get_outlines([data[0]['paragraphs']], [data[0]['tree']])"
      ],
      "id": "RkmXINGAoG2B"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpclBBYffxaL"
      },
      "source": [
        "##### Model 2: Greedy decoding + LCA loss"
      ],
      "id": "HpclBBYffxaL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgFl1lNDWKmv"
      },
      "outputs": [],
      "source": [
        "class GreedyDecoder:\n",
        "    def __init__(self, thresholds, similarity, encode):\n",
        "        self.thresholds = thresholds\n",
        "        self.similarity = similarity\n",
        "        self.encode = encode\n",
        "    \n",
        "    # add level and parent info to a tree rooted at node\n",
        "    def update_levels_parents(self, node, depth):\n",
        "        # print(node.text)\n",
        "        if len(node.children) == 0: # leaf paragraph node\n",
        "            node.level = -1\n",
        "            return\n",
        "        node.level = depth\n",
        "        for ch in node.children:\n",
        "            ch.linkParent(node)\n",
        "            self.update_levels_parents(ch, depth+1)\n",
        "\n",
        "    # decodes and returns tree rooted at node\n",
        "    def encode_decode(self, paragraphs):\n",
        "        embs = []\n",
        "        for para in paragraphs:\n",
        "            embs.append(self.encode(para))\n",
        "        return self.decode(embs)\n",
        "    \n",
        "    # decodes and returns tree rooted at node, with text fields populated, e.g. for printing the tree\n",
        "    def encode_decode_with_text(self, X, indexify=True):\n",
        "        root = self.encode_decode(X)\n",
        "        for idx, leaf in enumerate(preorder(root)):\n",
        "            if indexify:\n",
        "                leaf.text = idx\n",
        "            else:\n",
        "                leaf.text = X[idx]\n",
        "        return root\n",
        "    \n",
        "    # here X and y are lists\n",
        "    def batch_encode_decode_with_text(self, X):\n",
        "        roots = []\n",
        "        for X_i in X:\n",
        "            roots.append(self.encode_decode_with_text(X_i))\n",
        "        return roots\n",
        "\n",
        "    # bottom up decoding: for each depth, join paragraphs whose pairwise similarity reaches the threshold\n",
        "    # and represent them collectively by the mean of their embeddings\n",
        "    def decode(self, embs):\n",
        "        if len(embs) == 0:\n",
        "            return Node('', 0) # should never happen\n",
        "        roots = []\n",
        "        for i in range(len(embs)):\n",
        "            roots.append(Node(i, -1))\n",
        "        dim = embs[0].shape[0]\n",
        "        for depth in range(MAX_DEPTH-1): # in last layer, everything must be joined together\n",
        "            next_idxs = [[0]]\n",
        "            for i in range(1, len(embs)):\n",
        "                if self.similarity(embs[i-1], embs[i]) >= self.thresholds[depth]:\n",
        "                    next_idxs[-1].append(i)\n",
        "                else:\n",
        "                    next_idxs.append([i])\n",
        "\n",
        "            # print(next_idxs)\n",
        "            # for root in roots:\n",
        "            #     print_tree(root)\n",
        "\n",
        "            # update roots and embs\n",
        "            next_roots = []\n",
        "            next_embs = []\n",
        "            for comp in next_idxs:\n",
        "                # don't add trivial (1 -> 1) edges\n",
        "                if len(comp) == 1:\n",
        "                    next_roots.append(roots[comp[0]])\n",
        "                    next_embs.append(embs[comp[0]])\n",
        "                    continue\n",
        "\n",
        "                next_roots.append(Node('', -2)) # meaningless params since we only need tree structure\n",
        "                next_embs.append(torch.zeros(dim))\n",
        "                for idx in comp:\n",
        "                    next_roots[-1].insertChild(roots[idx])\n",
        "                    next_embs[-1] += embs[idx]\n",
        "                next_embs[-1] /= len(comp)\n",
        "            roots = next_roots\n",
        "            embs = next_embs\n",
        "        \n",
        "        # join everything together in the last layer\n",
        "        root = Node('', 0)\n",
        "        for node in roots:\n",
        "            root.insertChild(node)\n",
        "\n",
        "        # update parents and levels, then return\n",
        "        self.update_levels_parents(root, 0)\n",
        "        return root"
      ],
      "id": "MgFl1lNDWKmv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0Fpz1pEKcc3"
      },
      "outputs": [],
      "source": [
        "# y = indexified_tree(train_y[0].root)\n",
        "# print_tree(y)\n",
        "# compute_lca_dist(y, 2, 21)\n",
        "# compute_lca_dist(y, y_hat, len(train_X[0]))\n",
        "\n",
        "# greedy = GreedyDecoder([2,3,2,5,5,5,10,10], similarity=doc2vec_sim, encode=doc2vec_enc)\n",
        "# roots = greedy.batch_encode_decode_with_text([train_X[0]], [train_y[0]])"
      ],
      "id": "S0Fpz1pEKcc3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWo1Yua4hCjk"
      },
      "outputs": [],
      "source": [
        "def doc2vec_sim(v1, v2):\n",
        "    return torch.dot(v1, v2) / torch.norm(torch.sub(v1, v2))\n",
        "def doc2vec_enc(v):\n",
        "    return torch.tensor(doc2vec_model.infer_vector(word_tokenize(v)))\n",
        "\n",
        "def simcse_enc(v):\n",
        "    para = re.sub('\\n', '', v)\n",
        "    sents = re.split('[.]|[!]|[?]', para.strip())\n",
        "    with io.capture_output() as captured:\n",
        "        vecs = simcse_model.encode(sents, device=device, batch_size=len(sents))\n",
        "    return torch.mean(vecs, dim=0)"
      ],
      "id": "rWo1Yua4hCjk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njWi7UimNnjJ"
      },
      "outputs": [],
      "source": [
        "def evaluate_thresholds(X, y, thresholds, similarity=doc2vec_sim, encode=doc2vec_enc):\n",
        "    greedy = GreedyDecoder(thresholds, similarity=similarity, encode=encode)\n",
        "    y_hat = greedy.batch_encode_decode_with_text(X)\n",
        "    y = [indexified_tree(y_i.root) for y_i in y]\n",
        "    lens = [len(x) for x in X]\n",
        "    return batch_lca_loss(y, y_hat, lens)\n",
        "    # print('Actual:')\n",
        "    # print_tree(y_hat[0])\n",
        "    # print('Predicted:')\n",
        "    # print_tree(y[0])\n",
        "\n",
        "def random_search(X, y, n_tries=50, min_num=[0]*8, max_num=[3]*8, similarity=doc2vec_sim, encode=doc2vec_enc):\n",
        "    results = []\n",
        "    for i in range(n_tries):\n",
        "        print('try #' + str(i))\n",
        "        thresholds = []\n",
        "        for j in range(8):\n",
        "            thresholds.append(random.uniform(min_num[j],max_num[j]))\n",
        "        # print('thresholds:', thresholds)\n",
        "        loss = evaluate_thresholds(X, y, thresholds, similarity=similarity, encode=encode)\n",
        "        results.append({'loss':loss, 'thresholds':thresholds})\n",
        "    \n",
        "    # print sorted version by each index\n",
        "    print('printing sorted by component...')\n",
        "    for i in range(8):\n",
        "        print('component', i)\n",
        "        results_sorted = sorted(results, key=lambda x: x['thresholds'][i])\n",
        "        for result in results_sorted:\n",
        "            thresh =  [\"{0:0.5f}\".format(i) for i in result['thresholds']]\n",
        "            print(result['loss'], '\\t', thresh)\n",
        "        print()"
      ],
      "id": "njWi7UimNnjJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP42xnCssegT"
      },
      "outputs": [],
      "source": [
        "random_search(train_X[20:40], train_y[20:40], n_tries=10, encode=doc2vec_enc, min_num=[0,0,0,0,0,0,0,0], max_num=[3,3,3,3,3,3,3,3])"
      ],
      "id": "EP42xnCssegT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cUSNy2ATU6C"
      },
      "outputs": [],
      "source": [
        "def add_tree_breaks(node, breaks, cur_breaks, depths, depth):\n",
        "    if node.level == -1: # this is paragraph node, not a heading\n",
        "        depths.append(depth)\n",
        "        breaks.append(cur_breaks)\n",
        "        return\n",
        "    for child in node.children:\n",
        "        if child == node.children[0]: # first entry\n",
        "            cur_breaks += 1\n",
        "            depth = node.level\n",
        "        if child == node.children[-1]:\n",
        "            cur_breaks = 0\n",
        "            depth = 0\n",
        "        add_tree_breaks(child, breaks, cur_breaks, depths, depth)\n",
        "        if child == node.children[0]:\n",
        "            cur_breaks = 0\n",
        "            depth = 0\n",
        "        if child == node.children[-1]:\n",
        "            cur_breaks = 0\n",
        "            depth = 0\n",
        "    cur_breaks = 0\n",
        "\n",
        "def get_breaks(paras, trees):\n",
        "    max_paras = max([len(x) for x in paras])\n",
        "    breaks = []\n",
        "    depths = []\n",
        "    for tree in trees:\n",
        "        breaks_i = []\n",
        "        depths_i = []\n",
        "        add_tree_breaks(tree.root, breaks_i, 0, depths_i, 0)\n",
        "        breaks_i = torch.tensor(breaks_i)\n",
        "        depths_i[0] += 1\n",
        "        depths_i = torch.tensor(depths_i)\n",
        "        breaks.append(breaks_i)\n",
        "        depths.append(depths_i)\n",
        "    return breaks, depths\n",
        "\n",
        "def convert_dataset(dataset, window_size):\n",
        "  breaks, depths = get_breaks([d['paragraphs'] for d in dataset], [d['tree'] for d in dataset])\n",
        "  X = []\n",
        "  D = []\n",
        "  y = []\n",
        "  for i in tqdm(range(len(dataset))):  # for article\n",
        "      # print('{}'.format(100 * i / len(dataset)))\n",
        "      article = dataset[i]['paragraphs']\n",
        "      for p in range(1, len(article)):  # for para in article (excluding first, since its clearly always a break)\n",
        "          depth = depths[i][p]\n",
        "          isBreak = breaks[i][p]\n",
        "          for b in range(1, depth + 1):  # for depths <= depth of para\n",
        "              context = []\n",
        "              for j in range(p - window_size, p + window_size + 1):  # for para in context\n",
        "                  if j < 0 or j >= len(article):\n",
        "                      context.append(None)\n",
        "                  else:\n",
        "                      context.append(article[j])\n",
        "              X.append(context)\n",
        "              D.append(np.array([b]))\n",
        "              val = 1 if b > depth - isBreak else 0  # 1 if target para is first after break at depth b\n",
        "              y.append(np.array([val]))\n",
        "          if depth == 0:\n",
        "              for b in range(1, 8):  # MAX_DEPTH is 8\n",
        "                  context = []\n",
        "                  for j in range(p - window_size, p + window_size + 1):  # for para in context\n",
        "                      if j < 0 or j >= len(article):\n",
        "                        context.append(None)\n",
        "                      else:\n",
        "                        context.append(article[j])\n",
        "                  X.append(context)\n",
        "                  D.append(np.array([0]))\n",
        "                  y.append(np.array([0]))\n",
        "  return X, torch.tensor(np.stack(D, axis=0)), torch.tensor(np.stack(y, axis=0))\n",
        "\n",
        "def get_split_data(data, window_size, train_ratio=0.8, val_ratio=0.0001, test_ratio=0.0001):\n",
        "    random.shuffle(data)\n",
        "    n_data = len(data)\n",
        "    train_idx = int(train_ratio * n_data)\n",
        "    val_idx = int((train_ratio + val_ratio) * n_data)\n",
        "    test_idx = int((train_ratio + val_ratio + test_ratio) * n_data)\n",
        "    print('getting training data')\n",
        "    train_data = convert_dataset(data[:train_idx], window_size=window_size)\n",
        "    print('getting val data')\n",
        "    val_data = convert_dataset(data[train_idx:val_idx], window_size=window_size)\n",
        "    print('getting test data')\n",
        "    test_data = convert_dataset(data[val_idx:test_idx], window_size=window_size)\n",
        "    return train_data, val_data, test_data\n",
        "\n",
        "# iterate over batches of data and labels\n",
        "def batch_iter(data, batch_size, shuffle=False):\n",
        "    X, D, y = data\n",
        "    batch_num = math.ceil(len(X) / batch_size)\n",
        "    index_array = list(range(len(X)))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.shuffle(index_array)\n",
        "\n",
        "    for i in range(batch_num):\n",
        "        indices = index_array[i * batch_size: (i + 1) * batch_size]\n",
        "        batch_data_X = [X[idx] for idx in indices]\n",
        "        batch_data_D = D[indices]\n",
        "        batch_data_y = y[indices]\n",
        "\n",
        "        yield batch_data_X, batch_data_D, batch_data_y\n",
        "\n",
        "# MODULES FOR EMBEDDING 3 DIFFERENT WAYS: DOC2VEC, PROJECTED SIMCSE, PROJECTED FASTTEXT\n",
        "# each one takes a batch of lists of paragraphs, outputs a batch of concatenated paragraph embeddings\n",
        "# forward pass input: batch (len B) of list of paragraphs (len 2 * window_size + 1), each para variable length\n",
        "# forward pass output: tensor of size B x ((2 * window_size + 1) * emb_dim)\n",
        "class Doc2VecEmbedding(nn.Module):\n",
        "  def __init__(self, window_size, emb_dim): \n",
        "    super().__init__()\n",
        "    self.emb_dim = emb_dim\n",
        "    self.doc2vec = Doc2Vec.load(\"models/{}_d2v.model\".format(emb_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    with torch.no_grad():\n",
        "      batch = []\n",
        "      for b in x:\n",
        "        paras = []\n",
        "        for p in b:\n",
        "          paras.append(self.doc2vec.infer_vector(word_tokenize(p.lower())) if p is not None else np.zeros(shape=(self.emb_dim)))\n",
        "        batch.append(np.concatenate(paras, axis=0))\n",
        "      return torch.tensor(np.stack(batch, axis=0)).to(device)\n",
        "\n",
        "class SimCSEEmbedding(nn.Module):\n",
        "  def __init__(self, window_size, emb_dim, dropout): \n",
        "    super().__init__()\n",
        "    self.window_size = window_size\n",
        "    self.emb_dim = emb_dim\n",
        "    self.simcse = SimCSE(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
        "    self.SIMCSE_DIM = 768 # dim of simcse sentence embeddings\n",
        "    self.lstm = nn.LSTM(input_size=self.SIMCSE_DIM,\n",
        "                        hidden_size=int(emb_dim / 4),\n",
        "                        num_layers=1,\n",
        "                        bidirectional=True,\n",
        "                        batch_first=True, \n",
        "                        dropout=0.0).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B = len(x)  # batch size\n",
        "    batch = []\n",
        "    with torch.no_grad():\n",
        "      for b in x:\n",
        "        for p in b:\n",
        "          if p is not None:\n",
        "            p = re.sub('\\n', '', p)\n",
        "            sents = re.split('[.]|[!]|[?]', p.strip())\n",
        "            with io.capture_output() as captured:\n",
        "                sents_emb = self.simcse.encode(sents, device=device, batch_size=len(sents), max_length=128)  # a tensor of len(sents) x SIMCSE_DIM\n",
        "            batch.append(sents_emb)\n",
        "          else:\n",
        "            batch.append(torch.zeros((1, self.SIMCSE_DIM), device=device))\n",
        "      batch_emb = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True).to(device)\n",
        "      packed_in = torch.nn.utils.rnn.pack_padded_sequence(batch_emb, torch.tensor([a.shape[0] for a in batch_emb]), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "    _, (hidden, cell) = self.lstm(packed_in.to(device))\n",
        "    para_embs = torch.cat((hidden[0], cell[0], hidden[1], cell[1]), dim=1)        \n",
        "      \n",
        "    return para_embs.reshape(B, (2 * self.window_size + 1) * self.emb_dim)\n",
        "\n",
        "\n",
        "#### HERE\n",
        "class FastTextEmbedding(nn.Module):\n",
        "  def __init__(self, window_size, emb_dim, dropout): \n",
        "    super().__init__()\n",
        "    self.window_size = window_size\n",
        "    self.emb_dim = emb_dim\n",
        "    self.fasttext = FastText.load_fasttext_format('models/fast-text-300.bin')\n",
        "    self.FASTTEXT_DIM = 300 # dim of fasttext word embeddings\n",
        "    self.lstm = nn.LSTM(input_size=self.FASTTEXT_DIM,\n",
        "                        hidden_size=int(emb_dim / 4),\n",
        "                        num_layers=1,\n",
        "                        bidirectional=True,\n",
        "                        batch_first=True, \n",
        "                        dropout=0.0).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B = len(x)  # batch size\n",
        "    batch = []\n",
        "    with torch.no_grad():\n",
        "      for b in x:\n",
        "        for p in b:\n",
        "          if p is not None:\n",
        "            p = re.sub('\\n', '', p)\n",
        "            words = re.sub(\"[^\\s\\w]\", \"\", p.strip()).split(' ')\n",
        "            words = list(filter(None, words))\n",
        "            words_emb = torch.stack([torch.tensor(self.fasttext[word]) for word in words]).to(device)  # a tensor of len(words) x FASTTEXT_DIM\n",
        "            batch.append(words_emb)\n",
        "          else:\n",
        "            batch.append(torch.zeros((1, self.FASTTEXT_DIM), device=device))\n",
        "      batch_emb = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True).to(device)\n",
        "      packed_in = torch.nn.utils.rnn.pack_padded_sequence(batch_emb, torch.tensor([a.shape[0] for a in batch_emb]), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "    _, (hidden, cell) = self.lstm(packed_in.to(device))\n",
        "    para_embs = torch.cat((hidden[0], cell[0], hidden[1], cell[1]), dim=1)        \n",
        "      \n",
        "    return para_embs.reshape(B, (2 * self.window_size + 1) * self.emb_dim)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, layer_dims, window_size, emb_dim, emb_method, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.emb_dim = emb_dim # dimension of each paragraph embedding\n",
        "        if emb_method == 'doc2vec':\n",
        "          self.emb = Doc2VecEmbedding(window_size, emb_dim)\n",
        "        elif emb_method == 'simcse':\n",
        "          self.emb = SimCSEEmbedding(window_size, emb_dim, dropout=dropout)\n",
        "        elif emb_method == 'fasttext':\n",
        "          self.emb = FastTextEmbedding(window_size, emb_dim, dropout=dropout)\n",
        "        else:\n",
        "          raise NotImplementedError()\n",
        "\n",
        "        in_feats = (2 * window_size + 1) * self.emb_dim\n",
        "        self.layers = []\n",
        "        for dim in layer_dims:\n",
        "          self.layers.append(nn.Linear(in_features=in_feats + 1, out_features=dim))\n",
        "          in_feats = dim\n",
        "        self.layers.append(nn.Linear(in_features=in_feats + 1, out_features=1))\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, d):\n",
        "      '''\n",
        "      x is a batch (list) of windows (list) of paragraphs, which are strings\n",
        "      d is the depths for the whole batch (tensor)\n",
        "      '''\n",
        "      B = len(x)\n",
        "      x = self.emb(x).float()  # x is a (B x (2W + 1) x E) tensor\n",
        "      x = x.reshape(B, (2 * self.window_size + 1) * self.emb_dim)\n",
        "      for layer in self.layers[:-1]:\n",
        "        x = F.relu(layer(torch.cat((x, d), dim=1)))\n",
        "      x = self.dropout(x)\n",
        "      x = torch.sigmoid(self.layers[-1](torch.cat((x, d), dim=1)))\n",
        "      return x\n",
        "\n",
        "  def recursive_outline(self, subarticle, node):\n",
        "    if len(subarticle) == 1:\n",
        "        new = Node(subarticle[0], -1)\n",
        "        new.linkParent(node)\n",
        "        node.insertChild(new)\n",
        "        return\n",
        "    outs = [False]\n",
        "    for p in range(1, len(subarticle)):\n",
        "        context = []\n",
        "        for j in range(p - self.window_size, p + self.window_size + 1):\n",
        "            if j < 0 or j >= len(subarticle):\n",
        "                context.append(None)\n",
        "            else:\n",
        "                context.append(subarticle[j])\n",
        "        X = [context]\n",
        "        D = torch.tensor([node.level + 1]).to(device).unsqueeze(dim=0)\n",
        "        out = self.forward(X, D).squeeze()\n",
        "        outs.append(out.cpu().item() > 0.97)\n",
        "    prev = 0\n",
        "    flag = True\n",
        "    for o in range(len(outs)):\n",
        "        if outs[o]:\n",
        "            new = Node('', node.level + 1)\n",
        "            new.linkParent(node)\n",
        "            node.insertChild(new)\n",
        "            self.recursive_outline(subarticle[prev:o], new)\n",
        "            prev = o\n",
        "            flag = False\n",
        "    if flag:\n",
        "      for p in range(len(subarticle)):\n",
        "        new = Node(subarticle[p], -1)\n",
        "        new.linkParent(node)\n",
        "        node.insertChild(new)\n",
        "\n",
        "        # else:\n",
        "        #     new = Node(subarticle[o], -1)\n",
        "        #     new.linkParent(node)\n",
        "        #     node.insertChild(new)\n",
        "    else:\n",
        "       new = Node('', node.level + 1)\n",
        "       new.linkParent(node)\n",
        "       node.insertChild(new)\n",
        "       self.recursive_outline(subarticle[prev:], new)\n",
        "    return\n",
        "\n",
        "  def outline(self, article, wordy=False):\n",
        "      self.eval()\n",
        "      root = Node('root', 1)\n",
        "      self.recursive_outline(article, root)\n",
        "      new = Node(article[0], -1)\n",
        "      curr = root\n",
        "      while len(curr.children) > 0 and curr.level != -1:\n",
        "        curr = curr.children[0]\n",
        "      new.linkParent(curr.parent)\n",
        "      curr.parent.insertChild(new)\n",
        "      if len(article) > 1:\n",
        "          new = Node(article[len(article)-1], -1)\n",
        "          curr = root\n",
        "          while len(curr.children) > 0 and curr.level != -1:\n",
        "            curr = curr.children[-1]\n",
        "          new.linkParent(curr.parent)\n",
        "          curr.parent.insertChild(new)\n",
        "\n",
        "      def printNode(curNode):\n",
        "          print(curNode.level, '       ', curNode.text)\n",
        "          if curNode.level == -1:\n",
        "              return\n",
        "\n",
        "          for child in curNode.children:\n",
        "              printNode(child)\n",
        "          return\n",
        "\n",
        "      if wordy:\n",
        "        printNode(root)\n",
        "      return root\n",
        "\n",
        "  def save(self, path: str):\n",
        "      \"\"\" Save the model to a file.\n",
        "      @param path (str): path to the model\n",
        "      \"\"\"\n",
        "\n",
        "      params = {\n",
        "          # 'args': dict(hid_dim=self.hid_dim, n_layers=self.n_layers, num_heads=self.num_heads,\n",
        "          #       num_enc_layers=self.num_enc_layers, num_dec_layers=self.num_dec_layers, ff_dim=self.ff_dim, dropout=self.dropout),\n",
        "          'state_dict': self.state_dict()\n",
        "      }\n",
        "\n",
        "      torch.save(params, path)"
      ],
      "id": "5cUSNy2ATU6C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltaPAg3hSu8f"
      },
      "outputs": [],
      "source": [
        "# getting losses from recursive MLP\n",
        "\n",
        "# MODEL SPECS\n",
        "WINDOW_SIZE = 3  # number of neighbors to consider in each direction\n",
        "EMB_DIM = 256  # dim each paragraph becomes, via magic :)\n",
        "EMB_METHOD = 'doc2vec'  # one of 'doc2vec', 'simcse', 'fasttext'\n",
        "MLP_ARCHITECTURE = [1024, 256, 64]  # sizes of hidden layers in MLP\n",
        "\n",
        "model = MLP(layer_dims=MLP_ARCHITECTURE, window_size=WINDOW_SIZE, emb_dim=EMB_DIM, emb_method=EMB_METHOD)\n",
        "\n",
        "# EVAL STUFF\n",
        "params = torch.load('checkpoints/mlp_{}.bin'.format(EMB_METHOD), map_location=lambda storage, loc: storage)\n",
        "model.load_state_dict(params['state_dict'])\n",
        "model = model.to(device)"
      ],
      "id": "ltaPAg3hSu8f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uf-FPRECUs9n"
      },
      "outputs": [],
      "source": [
        "X = test_X\n",
        "y = test_y\n",
        "roots = [indexified_tree(model.outline(a)) for a in X]\n",
        "golds = [indexified_tree(a.root) for a in y]\n",
        "lens = [len(a) for a in X]\n",
        "# batch_lca_loss(roots, golds, lens)\n",
        "y_hat = roots\n",
        "y = golds"
      ],
      "id": "uf-FPRECUs9n"
    },
    {
      "cell_type": "code",
      "source": [
        "batch_lca_loss(roots, golds, lens)"
      ],
      "metadata": {
        "id": "jVauiLjiDXY3"
      },
      "id": "jVauiLjiDXY3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPYJXOv5boxM"
      },
      "outputs": [],
      "source": [
        "thresholds = [1.769, 1.261, 0.007, 2.289, 1.793, 0.590, 3.620, 3.969] # 128 thresholds\n",
        "# thresholds = [1.769, 1.261, 0.007, 2.289, 1.793, 0.590, 3.620, 3.969] # 256 thresholds\n",
        "# thresholds = [1.668, 0.429, 0.810, 2.581, 1.015, 1.205, 1.755, 0.440] # simcse thresholds\n",
        "X = test_X\n",
        "y = test_y\n",
        "\n",
        "greedy = GreedyDecoder(thresholds, similarity=doc2vec_sim, encode=doc2vec_enc)\n",
        "# greedy = GreedyDecoder(thresholds, similarity=doc2vec_sim, encode=simcse_enc)\n",
        "y_hat = greedy.batch_encode_decode_with_text(X)\n",
        "y = [indexified_tree(y_i.root) for y_i in y]\n",
        "lens = [len(x) for x in X]\n",
        "print(batch_lca_loss(y, y_hat, lens))\n",
        "\n",
        "# for i in range(10):\n",
        "#     print(i)\n",
        "#     print('Predicted:')\n",
        "#     print_tree(y_hat[i])\n",
        "#     print('Actual:')\n",
        "#     print_tree(y[i])"
      ],
      "id": "kPYJXOv5boxM"
    },
    {
      "cell_type": "code",
      "source": [
        "print_tree(y[5])"
      ],
      "metadata": {
        "id": "aCTXahlNCjlB"
      },
      "id": "aCTXahlNCjlB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_tree(y_hat[5])"
      ],
      "metadata": {
        "id": "XlsZ2WMBCz9X"
      },
      "id": "XlsZ2WMBCz9X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqzMYmxLwtpD"
      },
      "outputs": [],
      "source": [
        "print(batch_lca_loss(y, y_hat, lens))"
      ],
      "id": "KqzMYmxLwtpD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5Uh2CSQ3bJ2"
      },
      "outputs": [],
      "source": [
        "model_losses = []\n",
        "for len_i, y_i, y_hat_i in zip(lens, y, y_hat):\n",
        "    model_losses.append(lca_loss(y_i, y_hat_i, len_i))"
      ],
      "id": "p5Uh2CSQ3bJ2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWVHchil3ovC"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from google.colab import files\n",
        "\n",
        "with open(\"mlp_loss.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(model_losses)\n",
        "files.download('mlp_loss.csv')"
      ],
      "id": "SWVHchil3ovC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j2UAawngVgV"
      },
      "source": [
        "Here we simulate the degenerate output from the end-to-end model to get LCA loss of that model"
      ],
      "id": "1j2UAawngVgV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4uUx5hYl0sP"
      },
      "outputs": [],
      "source": [
        "bad_node = Node(-1,0)\n",
        "for i in range(100):\n",
        "    bad_node.insertChild(Node(i,-1))\n",
        "\n",
        "# thresholds = [1.769, 1.261, 0.007, 2.289, 1.793, 0.590, 3.620, 3.969]\n",
        "X = val_X\n",
        "y = val_y\n",
        "\n",
        "greedy = GreedyDecoder(thresholds, similarity=doc2vec_sim, encode=doc2vec_enc)\n",
        "y_hat = [bad_node]*len(y)\n",
        "y = [indexified_tree(y_i.root) for y_i in y]\n",
        "lens = [len(x) for x in X]\n",
        "print(batch_lca_loss(y, y_hat, lens))"
      ],
      "id": "z4uUx5hYl0sP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmhSuAZMgbYO"
      },
      "source": [
        "We can hard-code to extract specific results here:"
      ],
      "id": "rmhSuAZMgbYO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPaeL9nneQ-c"
      },
      "outputs": [],
      "source": [
        "val_y[10].root.text"
      ],
      "id": "dPaeL9nneQ-c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjFZlDETfXTI"
      },
      "outputs": [],
      "source": [
        "print_snippet_tree(textified_tree(y_hat[7], val_X[7]))"
      ],
      "id": "fjFZlDETfXTI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHzt_3Bug96V"
      },
      "outputs": [],
      "source": [
        "print_snippet_tree(textified_tree(y[7], val_X[7]))"
      ],
      "id": "CHzt_3Bug96V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2KLLiYbO87K"
      },
      "outputs": [],
      "source": [
        "evaluate_thresholds(train_X[:100], train_y[:100], [1.3,3,2,2,8,8,8,8])"
      ],
      "id": "B2KLLiYbO87K"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wStwFp0dgjKJ"
      },
      "source": [
        "And here we look at the doc2vec distributions"
      ],
      "id": "wStwFp0dgjKJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZNawe-4QdLy"
      },
      "outputs": [],
      "source": [
        "# investigate distribution of Doc2Vec distributions\n",
        "def plot_similarity_distribution(similarity=doc2vec_sim, encode=simcse_enc):\n",
        "    sims = []\n",
        "    n = len(train_X[0])\n",
        "    for x in range(n):\n",
        "        for y in range(x+1,n):\n",
        "            # print(doc2vec_enc(train_X[0][x]), doc2vec_enc(train_X[0][y]))\n",
        "            sims.append(similarity(encode(train_X[0][x]), encode(train_X[0][y])))\n",
        "    plt.hist(sims)\n",
        "    plt.xlabel('Similarity')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()"
      ],
      "id": "WZNawe-4QdLy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7wFwTidrCH4"
      },
      "outputs": [],
      "source": [
        "plot_similarity_distribution()"
      ],
      "id": "f7wFwTidrCH4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc5HGcLzgoFv"
      },
      "source": [
        "##### Model 3: Recursive split MLP -- note this code may have a decoding bug"
      ],
      "id": "yc5HGcLzgoFv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr1puvn7hOmI"
      },
      "outputs": [],
      "source": [
        "WINDOW_SIZE = 2  # WINDOW_SIZE paragraphs on each side of target para are considered\n",
        "DOC2VEC_DIM = 128"
      ],
      "id": "Lr1puvn7hOmI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvpuvYJnhci0"
      },
      "outputs": [],
      "source": [
        "def add_tree_breaks(node, breaks, cur_breaks, depths, depth):\n",
        "    if node.level == -1: # this is paragraph node, not a heading\n",
        "        depths.append(depth)\n",
        "        breaks.append(cur_breaks)\n",
        "        return\n",
        "    for child in node.children:\n",
        "        if child == node.children[0]: # first entry\n",
        "            cur_breaks += 1\n",
        "            depth = node.level\n",
        "        if child == node.children[-1]:\n",
        "            cur_breaks = 0\n",
        "            depth = 0\n",
        "        add_tree_breaks(child, breaks, cur_breaks, depths, depth)\n",
        "        if child == node.children[0]:\n",
        "            cur_breaks = 0\n",
        "            depth = 0\n",
        "        if child == node.children[-1]:\n",
        "            cur_breaks = 0\n",
        "            depth = 0\n",
        "    cur_breaks = 0\n",
        "\n",
        "def get_breaks(paras, trees):\n",
        "    max_paras = max([len(x) for x in paras])\n",
        "    breaks = []\n",
        "    depths = []\n",
        "    for tree in trees:\n",
        "        breaks_i = []\n",
        "        depths_i = []\n",
        "        add_tree_breaks(tree.root, breaks_i, 0, depths_i, 0)\n",
        "        breaks_i = torch.tensor(breaks_i)\n",
        "        depths_i[0] += 1\n",
        "        depths_i = torch.tensor(depths_i)\n",
        "        breaks.append(breaks_i)\n",
        "        depths.append(depths_i)\n",
        "    return breaks, depths\n",
        "\n",
        "def convert_dataset(dataset):\n",
        "  breaks, depths = get_breaks([d['paragraphs'] for d in dataset], [d['tree'] for d in dataset])\n",
        "  X = []\n",
        "  D = []\n",
        "  y = []\n",
        "  for i in range(len(dataset)):  # for article\n",
        "      print('{}'.format(100 * i / len(dataset)))\n",
        "      article = dataset[i]['paragraphs']\n",
        "      for p in range(1, len(article)):  # for para in article (excluding first, since its clearly always a break)\n",
        "          depth = depths[i][p]\n",
        "          isBreak = breaks[i][p]\n",
        "          for b in range(1, depth + 1):  # for depths <= depth of para\n",
        "              context = []\n",
        "              for j in range(p - WINDOW_SIZE, p + WINDOW_SIZE + 1):  # for para in context\n",
        "                  if j < 0 or j >= len(article):\n",
        "                      context.append(np.zeros([DOC2VEC_DIM]))\n",
        "                  else:\n",
        "                      context.append(doc2vec_model.infer_vector(word_tokenize(article[j].lower())))\n",
        "              X.append(np.concatenate(context, axis=0))\n",
        "              D.append(np.array([b]))\n",
        "              val = 1 if b > depth - isBreak else 0  # 1 if target para is first after break at depth b\n",
        "              y.append(np.array([val]))\n",
        "          if depth == 0:\n",
        "              for b in range(1, MAX_DEPTH):\n",
        "                  context = []\n",
        "                  for j in range(p - WINDOW_SIZE, p + WINDOW_SIZE + 1):  # for para in context\n",
        "                      if j < 0 or j >= len(article):\n",
        "                          context.append(np.zeros([DOC2VEC_DIM]))\n",
        "                      else:\n",
        "                          context.append(doc2vec_model.infer_vector(word_tokenize(article[j].lower())))\n",
        "                  X.append(np.concatenate(context, axis=0))\n",
        "                  D.append(np.array([0]))\n",
        "                  y.append(np.array([0]))\n",
        "  return np.stack(X, axis=0), np.stack(D, axis=0), np.stack(y, axis=0)"
      ],
      "id": "cvpuvYJnhci0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ce1cQI_hjKm"
      },
      "outputs": [],
      "source": [
        "def get_split_data(data, train_ratio=0.0008, val_ratio=0.0001, test_ratio=0.0001):\n",
        "    random.shuffle(data)\n",
        "    n_data = len(data)\n",
        "    train_idx = int(train_ratio * n_data)\n",
        "    val_idx = int((train_ratio + val_ratio) * n_data)\n",
        "    test_idx = int((train_ratio + val_ratio + test_ratio) * n_data)\n",
        "    train_data = convert_dataset(data[:train_idx])\n",
        "    val_data = convert_dataset(data[train_idx:val_idx])\n",
        "    test_data = convert_dataset(data[val_idx:test_idx])\n",
        "    return train_data, val_data, test_data"
      ],
      "id": "1Ce1cQI_hjKm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQIdIQvAheHi"
      },
      "outputs": [],
      "source": [
        "train_data, val_data, test_data = get_split_data(data)"
      ],
      "id": "uQIdIQvAheHi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5oIYe9shkio"
      },
      "outputs": [],
      "source": [
        "# iterate over batches of data and labels\n",
        "# articles in batch are sorted by descending num paragraphs for efficient packing/LSTM inference\n",
        "def batch_iter(data, batch_size, shuffle=False):\n",
        "    batch_num = math.ceil(len(dataX) / batch_size)\n",
        "    index_array = list(range(len(dataX)))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.shuffle(index_array)\n",
        "\n",
        "    for i in range(batch_num):\n",
        "        indices = index_array[i * batch_size: (i + 1) * batch_size]\n",
        "        batch_data_X = torch.tensor(dataX[indices])\n",
        "        batch_data_D = torch.tensor(dataD[indices])\n",
        "        batch_data_y = torch.tensor(datay[indices])\n",
        "\n",
        "        yield batch_data_X, batch_data_D, batch_data_y"
      ],
      "id": "D5oIYe9shkio"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2ayqAuIhqjt"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, layer_dims, dropout=0.1):\n",
        "        super().__init__()\n",
        "        in_feats = (2 * WINDOW_SIZE + 1) * DOC2VEC_DIM\n",
        "        self.layers = []\n",
        "        for dim in layer_dims:\n",
        "          self.layers.append(nn.Linear(in_features=in_feats + 1, out_features=dim))\n",
        "          in_feats = dim\n",
        "        self.layers.append(nn.Linear(in_features=in_feats + 1, out_features=1))\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, d):\n",
        "      for layer in self.layers[:-1]:\n",
        "        x = F.relu(layer(torch.cat((x, d), dim=1)))\n",
        "      x = self.dropout(x)\n",
        "      x = torch.sigmoid(self.layers[-1](torch.cat((x, d), dim=1)))\n",
        "      return x\n",
        "\n",
        "  def recursive_outline(self, subarticle, node):\n",
        "    if len(subarticle) == 1:\n",
        "        new = Node(subarticle[0], -1)\n",
        "        new.linkParent(node)\n",
        "        node.insertChild(new)\n",
        "        return\n",
        "    outs = [False]\n",
        "    for p in range(1, len(subarticle)):\n",
        "        context = []\n",
        "        for j in range(p - WINDOW_SIZE, p + WINDOW_SIZE + 1):\n",
        "            if j < 0 or j >= len(subarticle):\n",
        "                context.append(np.zeros([DOC2VEC_DIM]))\n",
        "            else:\n",
        "                context.append(doc2vec_model.infer_vector(word_tokenize(subarticle[j].lower())))\n",
        "        X = torch.tensor(np.concatenate(context, axis=0), device=device, dtype=torch.float32).unsqueeze(dim=0)\n",
        "        D = torch.tensor([node.level + 1]).to(device).unsqueeze(dim=0)\n",
        "        out = self.forward(X, D).squeeze()\n",
        "        outs.append(out.cpu().item() > 0.77)\n",
        "    prev = 0\n",
        "    flag = True\n",
        "    for o in range(len(outs)):\n",
        "        if outs[o]:\n",
        "            new = Node('', node.level + 1)\n",
        "            new.linkParent(node)\n",
        "            node.insertChild(new)\n",
        "            self.recursive_outline(subarticle[prev:o], new)\n",
        "            prev = o\n",
        "            flag = False\n",
        "    if flag:\n",
        "      for p in range(len(subarticle)):\n",
        "        new = Node(subarticle[p], -1)\n",
        "        new.linkParent(node)\n",
        "        node.insertChild(new)\n",
        "\n",
        "        # else:\n",
        "        #     new = Node(subarticle[o], -1)\n",
        "        #     new.linkParent(node)\n",
        "        #     node.insertChild(new)\n",
        "    else:\n",
        "       new = Node('', node.level + 1)\n",
        "       new.linkParent(node)\n",
        "       node.insertChild(new)\n",
        "       self.recursive_outline(subarticle[prev:], new)\n",
        "    return\n",
        "\n",
        "  def outline(self, article, wordy=False):\n",
        "      self.eval()\n",
        "      root = Node('root', 1)\n",
        "      self.recursive_outline(article, root)\n",
        "      new = Node(article[0], -1)\n",
        "      curr = root\n",
        "      while len(curr.children) > 0 and curr.level != -1:\n",
        "        curr = curr.children[0]\n",
        "      new.linkParent(curr.parent)\n",
        "      curr.parent.insertChild(new)\n",
        "      if len(article) > 1:\n",
        "          new = Node(article[len(article)-1], -1)\n",
        "          curr = root\n",
        "          while len(curr.children) > 0 and curr.level != -1:\n",
        "            curr = curr.children[-1]\n",
        "          new.linkParent(curr.parent)\n",
        "          curr.parent.insertChild(new)\n",
        "\n",
        "      def printNode(curNode):\n",
        "          print(curNode.level, '       ', curNode.text)\n",
        "          if curNode.level == -1:\n",
        "              return\n",
        "\n",
        "          for child in curNode.children:\n",
        "              printNode(child)\n",
        "          return\n",
        "\n",
        "      if wordy:\n",
        "        printNode(root)\n",
        "      return root\n",
        "\n",
        "  @staticmethod\n",
        "  def load(model_path: str):\n",
        "      \"\"\" Load the model from a file.\n",
        "      @param model_path (str): path to model\n",
        "      \"\"\"\n",
        "      params = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "      # args = params['args']\n",
        "      model = MLP(layer_dims=[1024, 256, 64])\n",
        "      model.load_state_dict(params['state_dict'])\n",
        "\n",
        "      return model\n",
        "\n",
        "  def save(self, path: str):\n",
        "      \"\"\" Save the model to a file.\n",
        "      @param path (str): path to the model\n",
        "      \"\"\"\n",
        "\n",
        "      params = {\n",
        "          # 'args': dict(hid_dim=self.hid_dim, n_layers=self.n_layers, num_heads=self.num_heads,\n",
        "          #       num_enc_layers=self.num_enc_layers, num_dec_layers=self.num_dec_layers, ff_dim=self.ff_dim, dropout=self.dropout),\n",
        "          'state_dict': self.state_dict()\n",
        "      }\n",
        "\n",
        "      torch.save(params, path)"
      ],
      "id": "K2ayqAuIhqjt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFhfncT-hruW"
      },
      "outputs": [],
      "source": [
        "def train(train_data, val_data, lr=0.002, batch_size=1, grad_clip=5.0, lr_decay=0.5,\n",
        "          max_epoch=50, log_every=5, valid_niter=25, max_patience=4, max_num_trial=5, model_path='model.bin'):\n",
        "    model = MLP(layer_dims=[1024, 256, 64])\n",
        "    model.train()\n",
        "\n",
        "    # # initialize model parameters\n",
        "    # for p in model.parameters():\n",
        "    #     p.data.uniform_(-0.1, 0.1)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('use device: %s' % device)\n",
        "\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    print('{} parameters!'.format(sum([np.prod(p.size()) for p in model_parameters])))\n",
        "\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "\n",
        "    num_trial = 0\n",
        "    train_iter = patience = cum_loss = report_loss = cum_tgt_words = report_tgt_words = 0\n",
        "    cum_examples = report_examples = epoch = valid_num = 0\n",
        "    hist_valid_scores = []\n",
        "    train_time = begin_time = time.time()\n",
        "    print('begin Maximum Likelihood training')\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    loss_fn = nn.BCELoss(reduction='sum')\n",
        "\n",
        "    train_X = np.load('train_X.npy', allow_pickle=True)\n",
        "    train_D = np.load('train_D.npy', allow_pickle=True)\n",
        "    train_y = np.load('train_y.npy', allow_pickle=True)\n",
        "    \n",
        "    # train_X, train_D, train_y = train_data\n",
        "    val_X, val_D, val_y = val_data\n",
        "\n",
        "    while True:\n",
        "        epoch += 1\n",
        "        batch_num = math.ceil(len(train_data) / batch_size)\n",
        "        current_iter = 0\n",
        "        for batch in batch_iter(train_data, batch_size=batch_size, shuffle=True):\n",
        "            X, D, y = convert_dataset(batch)\n",
        "            X = X.to(device)\n",
        "            D = D.to(device)\n",
        "            y = y.to(dtype=torch.float32, device=device)\n",
        "\n",
        "            model.train()\n",
        "            current_iter += 1\n",
        "            train_iter += 1\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            batch_size = len(X)\n",
        "            out = model(X, D)\n",
        "            train_loss = loss_fn(out, y)\n",
        "            train_loss.backward()\n",
        "\n",
        "            # clip gradient\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            report_loss += train_loss.item()\n",
        "            cum_loss += train_loss.item()\n",
        "            report_examples += batch_size\n",
        "            cum_examples += batch_size\n",
        "\n",
        "            if train_iter % log_every == 0:\n",
        "                print('epoch %d (%d / %d), iter %d, avg train loss %f, '\n",
        "                      'cum examples %d, time elapsed %.2f sec' %\n",
        "                      (epoch, current_iter, batch_num, train_iter,\n",
        "                       report_loss / report_examples,\n",
        "                       cum_examples,\n",
        "                       time.time() - begin_time))\n",
        "\n",
        "                train_time = time.time()\n",
        "                report_loss = report_examples = 0.\n",
        "\n",
        "            # perform validation\n",
        "            if train_iter % valid_niter == 0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    print('epoch %d, iter %d, cum loss %f, cum examples %d' % (epoch, train_iter,\n",
        "                            cum_loss / cum_examples,\n",
        "                            cum_examples))\n",
        "                    train_losses.append(cum_loss / cum_examples)\n",
        "                    cum_loss = cum_examples = 0.\n",
        "\n",
        "                    print('begin validation ...')\n",
        "\n",
        "                    val_cum_loss = 0.\n",
        "                    val_cum_examples = 0\n",
        "\n",
        "                    count = 0\n",
        "                    NUM_BATCHES = 8  # number of batches to validate over each time\n",
        "                    for batch in batch_iter(val_data, batch_size, shuffle=True):\n",
        "                        if count >= NUM_BATCHES:\n",
        "                            break\n",
        "                        X, D, y = convert_dataset(batch)\n",
        "                        X = X.to(device)\n",
        "                        D = D.to(device)\n",
        "                        y = y.to(dtype=torch.float32, device=device)\n",
        "\n",
        "                        batch_size = len(X)\n",
        "                        out = model(X, D)\n",
        "                        val_loss = loss_fn(out, y)\n",
        "                        val_cum_loss += val_loss.item()\n",
        "                        val_cum_examples += batch_size\n",
        "                        count += 1\n",
        "\n",
        "                    val_losses.append(val_cum_loss / val_cum_examples)\n",
        "                    valid_metric = -val_cum_loss / val_cum_examples # metric for evaluating whether model is improving on val data\n",
        "\n",
        "                    print('validation: iter %d, val loss %f' % (train_iter, val_cum_loss / val_cum_examples))\n",
        "\n",
        "                    is_better = len(hist_valid_scores) == 0 or valid_metric > max(hist_valid_scores)\n",
        "                    hist_valid_scores.append(valid_metric)\n",
        "\n",
        "                    if is_better:\n",
        "                        patience = 0\n",
        "                        print('epoch %d, iter %d: save currently the best model to [%s]' %\n",
        "                                (epoch, train_iter, model_path))\n",
        "                        model.save(model_path)\n",
        "                        torch.save(optimizer.state_dict(), model_path + '.optim')\n",
        "                        np.save('train.npy', np.array(train_losses))\n",
        "                        np.save('val.npy', np.array(val_losses))\n",
        "                    elif patience < max_patience:\n",
        "                        patience += 1\n",
        "                        print('hit patience %d' % patience)\n",
        "\n",
        "                        if patience == max_patience:\n",
        "                            num_trial += 1\n",
        "                            print('hit #%d trial' % num_trial)\n",
        "                            if num_trial == max_num_trial:\n",
        "                                print('early stop!')\n",
        "                                exit(0)\n",
        "\n",
        "                            # decay lr, and restore from previously best checkpoint\n",
        "                            lr = optimizer.param_groups[0]['lr'] * lr_decay\n",
        "                            print('load previously best model and decay learning rate to %f' % lr)\n",
        "\n",
        "                            # load model\n",
        "                            params = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "                            model.load_state_dict(params['state_dict'])\n",
        "                            model = model.to(device)\n",
        "                            train_losses = list(np.load('train.npy', allow_pickle=True))\n",
        "                            val_losses = list(np.load('val.npy', allow_pickle=True))\n",
        "\n",
        "                            print('restore parameters of the optimizers')\n",
        "                            optimizer.load_state_dict(torch.load(model_path + '.optim'))\n",
        "\n",
        "                            # set new lr\n",
        "                            for param_group in optimizer.param_groups:\n",
        "                                param_group['lr'] = lr\n",
        "\n",
        "                            # reset patience\n",
        "                            patience = 0\n",
        "\n",
        "        if epoch == max_epoch:\n",
        "            print('reached maximum number of epochs!')\n",
        "            break"
      ],
      "id": "kFhfncT-hruW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hy4A11xhwzd"
      },
      "outputs": [],
      "source": [
        "# train(train_data, val_data)\n",
        "model = MLP(layer_dims=[1024, 256, 64])\n",
        "params = torch.load('model.bin', map_location=lambda storage, loc: storage)\n",
        "model.load_state_dict(params['state_dict'])\n",
        "model = model.to(device)\n",
        "\n",
        "# article = data[20]['paragraphs']\n",
        "sample = data[200:350]\n",
        "roots = [indexified_tree(model.outline(a['paragraphs'])) for a in sample]\n",
        "golds = [indexified_tree(a['tree'].root) for a in sample]\n",
        "lens = [len(a['paragraphs']) for a in sample]\n",
        "batch_lca_loss(roots, golds, lens)"
      ],
      "id": "3hy4A11xhwzd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUazcP3Jkote"
      },
      "source": [
        "##### Human performance"
      ],
      "id": "MUazcP3Jkote"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fxv4m2Lkrjp"
      },
      "outputs": [],
      "source": [
        "def get_paragraphs_trees(data):\n",
        "    paras = [d['paragraphs'] for d in data]\n",
        "    trees = [d['tree'] for d in data]\n",
        "    return paras, trees\n",
        "\n",
        "def get_split_data(data, train_ratio=0.05, val_ratio=0.001, test_ratio=0.01):\n",
        "    random.shuffle(data)\n",
        "    n_data = len(data)\n",
        "    train_idx = int(train_ratio*n_data)\n",
        "    val_idx = int((train_ratio + val_ratio)*n_data)\n",
        "    test_idx = int((train_ratio + val_ratio + test_ratio)*n_data)\n",
        "    train_X, train_y = get_paragraphs_trees(data[:train_idx])\n",
        "    val_X, val_y = get_paragraphs_trees(data[train_idx:val_idx])\n",
        "    test_X, test_y = get_paragraphs_trees(data[val_idx:test_idx])\n",
        "    return train_X, train_y, val_X, val_y, test_X, test_y\n",
        "\n",
        "train_X, train_y, val_X, val_y, test_X, test_y = get_split_data(data)"
      ],
      "id": "2fxv4m2Lkrjp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNKULJxXlK9b"
      },
      "outputs": [],
      "source": [
        "test_X[3]"
      ],
      "id": "dNKULJxXlK9b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBy8GjAPYONc"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from google.colab import files\n",
        "\n",
        "with open(\"test_X.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(test_X)\n",
        "files.download('test_X.csv')"
      ],
      "id": "CBy8GjAPYONc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAKemnWSv4z6"
      },
      "outputs": [],
      "source": [
        "# from tree_utils import *"
      ],
      "id": "iAKemnWSv4z6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sq53vVSNEwdg"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from google.colab import files\n",
        "\n",
        "with open(\"test_y.pickle\", \"wb\") as f:\n",
        "    pickle.dump(test_y, f)\n",
        "files.download('test_y.pickle')"
      ],
      "id": "sq53vVSNEwdg"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "0ba86871",
        "e49e36c2",
        "FSKtCnA_BdMD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}